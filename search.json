[{"path":"https://krystynagrzesiak.github.io/miceDRF/articles/About_IScore.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Energy-I-Score: Implementation Details","text":"vignette presents implementation details energy--Score, metric designed evaluate quality imputation methods incomplete datasets. score based concept energy distance observed imputed distributions. allows comparing uncertainty induced imputation model variability present observed data. procedure model-agnostic: can used imputation method ‚Ñê\\mathcal{} multiple imputation draws. score distribution-free can applied : continuous variables, mixed-type data (score calculated dummy variables), multiple imputation methods.","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/articles/About_IScore.html","id":"notation","dir":"Articles","previous_headings":"Introduction","what":"Notation","title":"Energy-I-Score: Implementation Details","text":"Let X‚àà‚Ñùn√ópX \\\\mathbb{R}^{n \\times p} original dataset missing values, XÃÉ‚àà‚Ñùn√óp\\tilde{X} \\\\mathbb{R}^{n \\times p} imputed dataset, ‚Ñê\\mathcal{} imputation function, NN number imputations drawn ‚Ñê\\mathcal{}. , variable missing values j‚àà{1,‚Ä¶,p}j \\\\{1, \\ldots, p\\} define LjL_j set indices ii Xi,jX_{,j} observed, LjcL_j^c set indices ii Xi,jX_{,j} missing OjO_j set fully observed predictor variables rows Xi,jX_{,j} observed. Finally, define set variables missing values ùíÆ={j:Ljc‚â†‚àÖ}\\mathcal{S} = \\{ j : L_j^c \\neq \\emptyset \\}.","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/articles/About_IScore.html","id":"algorithm-overview","dir":"Articles","previous_headings":"Introduction","what":"Algorithm Overview","title":"Energy-I-Score: Implementation Details","text":"energy--Score computed iteratively variable missing data. following steps performed j‚ààùíÆj \\\\mathcal{S}.","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/articles/About_IScore.html","id":"step-1-selection-of-predictor-set","dir":"Articles","previous_headings":"Introduction > Algorithm Overview","what":"Step 1: Selection of Predictor Set","title":"Energy-I-Score: Implementation Details","text":"determine set predictor variables: Oj=‚ãÇm‚ààLj{l:ml=0}. O_j = \\bigcap_{m \\L_j} \\{ l : m_l = 0 \\}. OjO_j empty, algorithm automatically selects fallback variable k*k^* defined : k*=argmaxk‚â†j|{:mi,‚ãÖ‚ààLj‚à©Lk}|. k^* = \\text{argmax}_{k \\neq j} \\big|\\{ : m_{,\\cdot} \\L_j \\cap L_k \\}\\big|.  variable largest number observed values observed part column jj. ensures imputation model least one predictor.","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/articles/About_IScore.html","id":"step-2-data-partitioning","dir":"Articles","previous_headings":"Introduction > Algorithm Overview","what":"Step 2: Data Partitioning","title":"Energy-I-Score: Implementation Details","text":"data split training test sets follows: Train=[NAXÃÉLj,OjXÃÉLjc,jXÃÉLjc,Oj],Test=[XÃÉLj,j]. \\text{Train} = \\begin{bmatrix} \\mathrm{NA} & \\tilde{X}_{L_j, O_j} \\\\ \\tilde{X}_{L_j^c, j} & \\tilde{X}_{L_j^c, O_j} \\end{bmatrix}, \\quad \\text{Test} = \\begin{bmatrix} \\tilde{X}_{L_j, j} \\end{bmatrix}. training set contains observed predictor values missing target values imputed. test set contains observed target values evaluate imputation quality.","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/articles/About_IScore.html","id":"step-3-multiple-imputations","dir":"Articles","previous_headings":"Introduction > Algorithm Overview","what":"Step 3: Multiple Imputations","title":"Energy-I-Score: Implementation Details","text":"missing part training set imputed NN times using ‚Ñê\\mathcal{}: XÃÉ,j(1),‚Ä¶,XÃÉ,j(N)‚àºHXj|XOj,Mj=1. \\tilde{X}_{,j}^{(1)}, \\ldots, \\tilde{X}_{,j}^{(N)} \\sim H_{X_j|X_{O_j}, M_j = 1}. imputation represents draw conditional distribution missing variable given observed predictors.","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/articles/About_IScore.html","id":"step-4-energy-distance-calculation","dir":"Articles","previous_headings":"Introduction > Algorithm Overview","what":"Step 4: Energy Distance Calculation","title":"Energy-I-Score: Implementation Details","text":"‚ààLji \\L_j, energy--Score component computed : SÃÇNAj(H,P)=1|Lj|‚àë‚ààLj[12N2‚àël=1N‚àë‚Ñì=1N|XÃÉ,j(l)‚àíXÃÉ,j(‚Ñì)|‚àí1N‚àël=1N|XÃÉ,j(l)‚àíxi,j|]. \\widehat{S}^j_{\\mathrm{NA}}(H,P) =  \\frac{1}{|L_j|} \\sum_{\\L_j}  \\left[ \\frac{1}{2N^2} \\sum_{l=1}^N \\sum_{\\ell=1}^N  |\\tilde{X}_{,j}^{(l)} - \\tilde{X}_{,j}^{(\\ell)}| -  \\frac{1}{N} \\sum_{l=1}^N  |\\tilde{X}_{,j}^{(l)} - x_{,j}| \\right]. first term internal dispersion imputed values second term distance imputed actual observations. larger score, greater uncertainty imputation relative true data.","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/articles/About_IScore.html","id":"step-5-weighting","dir":"Articles","previous_headings":"Introduction > Algorithm Overview","what":"Step 5: Weighting","title":"Energy-I-Score: Implementation Details","text":"variable‚Äôs contribution final score weighted : wj=1n2|Lj|‚ãÖ|Ljc|. w_j = \\frac{1}{n^2} |L_j| \\cdot |L_j^c|. accounts relative amount missing observed data per variable.","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/articles/About_IScore.html","id":"step-6-final-score","dir":"Articles","previous_headings":"Introduction > Algorithm Overview","what":"Step 6: Final Score","title":"Energy-I-Score: Implementation Details","text":"final energy--Score weighted average variables missing values: SÃÇNA(H,P)=1|ùíÆ|‚àëj‚ààùíÆwjSÃÇNAj(H,P). \\widehat{S}_{\\mathrm{NA}}(H,P) = \\frac{1}{|\\mathcal{S}|} \\sum_{j \\\\mathcal{S}}  w_j \\widehat{S}^j_{\\mathrm{NA}}(H,P). scalar measure summarizes imputation uncertainty across dataset.","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/articles/About_IScore.html","id":"practical-interpretation","dir":"Articles","previous_headings":"Introduction","what":"Practical Interpretation","title":"Energy-I-Score: Implementation Details","text":"High values score suggest large variability poor alignment imputed observed distributions. Low values indicate imputations close observed data distribution (better performance). Variables missing values lower weight, many missing values contribute . Methods rely multiple imputation weak/random draw mechanism tend perform worse, underestimate uncertainty missing values. energy--Score primarily used rank different imputation methods, rather interpret absolute numeric value directly.","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/articles/About_IScore.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Energy-I-Score: Implementation Details","text":"approach follows methodology proposed N√§f, Grzesiak, Scornet (2025) ‚Äúrank imputation methods?‚Äù (arXiv:2507.11297).","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/articles/Example_IScore.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Energy-I-Score: First Steps","text":"vignette provides basic introduction using miceDRF package. install latest development version directly GitHub, run following code R console: installation, load package set random seed ensure reproducibility: begin loading example dataset windspeed mice package: Next, introduce missing values using ampute() function: Finally, let‚Äôs check proportion missing values column:","code":"if (!requireNamespace(\"devtools\", quietly = TRUE)) {   install.packages(\"devtools\") } devtools::install_github(\"KrystynaGrzesiak/miceDRF\") library(miceDRF)  set.seed(17) library(mice) #>  #> Attaching package: 'mice' #> The following object is masked from 'package:stats': #>  #>     filter #> The following objects are masked from 'package:base': #>  #>     cbind, rbind  head(windspeed) #>   RochePt Rosslare Shannon Dublin Clones MalinHead #> 1    4.92     7.29    3.67   3.71   2.71      7.83 #> 2   22.50    19.41   16.13  16.08  16.58     19.67 #> 3    7.54     9.29   11.00   1.71   9.71     15.37 #> 4    6.29     6.75    8.25   8.46  10.29     15.46 #> 5   10.34    11.29    9.38   8.71   8.42     11.12 #> 6   10.63    11.38    5.71   6.54   5.17      6.38 windspeed_miss <- ampute(windspeed, 0.2, mech  = \"MAR\")$amp colMeans(is.na(windspeed_miss)) #>    RochePt   Rosslare    Shannon     Dublin     Clones  MalinHead  #> 0.05080831 0.03695150 0.03233256 0.03002309 0.03002309 0.02309469"},{"path":"https://krystynagrzesiak.github.io/miceDRF/articles/Example_IScore.html","id":"imputation-function","dir":"Articles","previous_headings":"","what":"Imputation Function","title":"Energy-I-Score: First Steps","text":"can compute energy--Score, need define imputation method applied dataset missing values. miceDRF package flexible ‚Äî allows use imputation strategy, long function follows simple rules. imputation function: Must accept dataset missing values required argument. Must return dataset dimensions, missing values filled . require additional non-default arguments ‚Äî function called internally scoring procedure. simple custom function (e.g.¬†mean imputation), wrapper around complex method (e.g.¬†random forests, Bayesian models, mice, missForest), approach returns fully imputed dataset. example, let‚Äôs define zero imputation Additionally, miceDRF package provides convenient way quickly implement imputation methods mice package fully compatible energy--Score. can simply use create_mice_imputation() name method (list methods see ?mice::mice) random forest imputation:","code":"impute_zero <- function(X) { X[is.na(X)] <- 0; X } library(ranger)                                  # for random forest imputation impute_rf <- create_mice_imputation(\"rf\")"},{"path":"https://krystynagrzesiak.github.io/miceDRF/articles/Example_IScore.html","id":"energy-i-score","dir":"Articles","previous_headings":"","what":"Energy-I-Score","title":"Energy-I-Score: First Steps","text":"calculate Energy--Score need provide imputation method along incomplete imputed datasets. Let‚Äôs see example random forest imputation: result single score summarizing performance across columns required imputation. addition, table scores calculated column separately also returned attribute result. table says score, weight number columns used training part column. access table, simply use attr() function. Iscore() function exposes several parameters control Energy--Score computed. illustrate important ones concise examples. parameter N controls many times missing part re-imputed estimate score (relevant method multiple). Let us note deterministic methods, N effectively ignored (multiple = FALSE). working datasets contain many columns missing values, calculating energy--Score can time-consuming. make computation faster, can limit number columns used scoring setting max_length parameter. parameter defines many variables (columns) used compute score. function automatically selects variables largest number missing values first. default, max_length = NULL, means columns missing data included calculation. variables may lack fully observed predictors among rows needed training conditional imputations. Thus, can specify skip_if_needed = TRUE (default): try skip minimal rows obtain workable design; proceed scoring. skip_if_needed = FALSE: complete predictors can formed, score variable returned NA. Additionally, can adopt scaling scale = TRUE ensure variable standardized internally computing distances. prevents variables large numeric ranges dominating score.","code":"sc <- Iscore(windspeed_miss, impute_rf(windspeed_miss), imputation_func = impute_rf)  sc #> [1] 2.719471 #> attr(,\"dat\") #>           column_id     weight    score n_columns_used #> RochePt           1 0.04822683 2.865981              1 #> Rosslare          2 0.03558609 3.239500              1 #> Shannon           3 0.03128717 2.765237              1 #> Dublin            4 0.02912171 2.181387              1 #> Clones            5 0.02912171 1.986160              1 #> MalinHead         6 0.02256132 3.163669              1 attr(sc, \"dat\") #>           column_id     weight    score n_columns_used #> RochePt           1 0.04822683 2.865981              1 #> Rosslare          2 0.03558609 3.239500              1 #> Shannon           3 0.03128717 2.765237              1 #> Dublin            4 0.02912171 2.181387              1 #> Clones            5 0.02912171 1.986160              1 #> MalinHead         6 0.02256132 3.163669              1 Iscore(windspeed_miss, impute_rf(windspeed_miss), imputation_func = impute_rf, N = 5) #> [1] 3.520822 #> attr(,\"dat\") #>           column_id     weight    score n_columns_used #> RochePt           1 0.04822683 3.771838              1 #> Rosslare          2 0.03558609 3.616765              1 #> Shannon           3 0.03128717 3.867273              1 #> Dublin            4 0.02912171 3.082888              1 #> Clones            5 0.02912171 3.136965              1 #> MalinHead         6 0.02256132 3.413230              1 Iscore(windspeed_miss, impute_rf(windspeed_miss), imputation_func = impute_rf, max_length = 2) #> [1] 3.458355 #> attr(,\"dat\") #>          column_id     weight    score n_columns_used #> RochePt          1 0.04822683 3.332980              1 #> Rosslare         2 0.03558609 3.628264              1"},{"path":"https://krystynagrzesiak.github.io/miceDRF/articles/Example_IScore.html","id":"summary-of-best-practices","dir":"Articles","previous_headings":"Energy-I-Score","what":"Summary of best practices","title":"Energy-I-Score: First Steps","text":"Use multiple = TRUE genuinely multiple imputers determine N stable estimates. Consider scale = TRUE mixing variables different scales. Use max_length quick experiments; remove final runs. Keep skip_if_needed = TRUE unless explicitly want flag unscorable columns NA.","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/articles/Example_IScore.html","id":"comparisons-of-energy-i-scores","dir":"Articles","previous_headings":"Energy-I-Score","what":"Comparisons of energy-I-Scores","title":"Energy-I-Score: First Steps","text":"also provide functionality quick benchmarking different imputation methods. run Energy--Scores one imputation function , use Iscores_compare() function. simply need provide incomplete dataset list imputation functions, shown : example , compare random forest imputation simple zero imputation method. According results, random forest method yields lower Energy--Score, indicating better imputation quality compared zero imputation baseline.","code":"imputation_list <- list(rf = impute_rf, zero = impute_zero)  Iscores_compare(windspeed_miss, imputation_list, N = 10) #> [1] \"Calculating score for method: rf\" #> [1] \"Calculating score for method: zero\" #>        rf      zero  #>  3.083034 11.063610"},{"path":"https://krystynagrzesiak.github.io/miceDRF/articles/Example_IScore.html","id":"energy-i-score-for-mixed-datasets","dir":"Articles","previous_headings":"","what":"Energy-I-Score for mixed datasets","title":"Energy-I-Score: First Steps","text":"data mixed, .e.¬†contains categorical numerical variables, can use IScore_cat() function able calculate scores categorical columns. using make sure variables contain categorical values stored factors.","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/articles/Example_IScore.html","id":"energy-score","dir":"Articles","previous_headings":"","what":"Energy score","title":"Energy-I-Score: First Steps","text":"access original dataset imputation, can also use energy distance additional evaluation metric. package provides easy--use wrapper energy_dist() around energy::eqdist.e function energy package. can use providing complete imputed datasets:","code":"energy_dist(windspeed, impute_rf(windspeed_miss)) #> E-statistic  #>    0.763335  energy_dist(windspeed, impute_zero(windspeed_miss)) #> E-statistic  #>    29.18786"},{"path":"https://krystynagrzesiak.github.io/miceDRF/articles/Example_IScore.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Energy-I-Score: First Steps","text":"approach follows methodology proposed N√§f, Grzesiak, Scornet (2025) ‚Äúrank imputation methods?‚Äù (arXiv:2507.11297).","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Krystyna Grzesiak. Author, contributor. Jeffrey N√§f. Author, maintainer.","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Grzesiak K, N√§f J (2026). miceDRF: MICE Distributional Random Forest Imputation. R package version 0.1.0, https://github.com/KrystynaGrzesiak/miceDRF.","code":"@Manual{,   title = {miceDRF: MICE and Distributional Random Forest for Imputation},   author = {Krystyna Grzesiak and Jeffrey N√§f},   year = {2026},   note = {R package version 0.1.0},   url = {https://github.com/KrystynaGrzesiak/miceDRF}, }"},{"path":"https://krystynagrzesiak.github.io/miceDRF/index.html","id":"micedrf-imputation-with-mice-drf-and-i-score","dir":"","previous_headings":"","what":"MICE and Distributional Random Forest for Imputation","title":"MICE and Distributional Random Forest for Imputation","text":"miceDRF R package extends functionality mice package providing new method handling missing data using Distributed Random Forests (DRF).","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"MICE and Distributional Random Forest for Imputation","text":"install latest development version directly GitHub, run following code R console:","code":"if (!requireNamespace(\"devtools\", quietly = TRUE)) {   install.packages(\"devtools\") } devtools::install_github(\"KrystynaGrzesiak/miceDRF\")"},{"path":"https://krystynagrzesiak.github.io/miceDRF/index.html","id":"example-usage","dir":"","previous_headings":"","what":"Example usage","title":"MICE and Distributional Random Forest for Imputation","text":"","code":"library(miceDRF) library(mice)  # Generate a random dataset n <- 200 d <- 5 X <- matrix(runif(n * d), nrow = n, ncol = d)  # Introduce missing values pmiss <- 0.2 X.NA <- apply(X, 2, function(x) {   U <- runif(length(x))   ifelse(U <= pmiss, NA, x) })  # Perform imputation with DRF method imp <- mice(X.NA, m = 1, method = \"DRF\") Ximp <- complete(imp)"},{"path":"https://krystynagrzesiak.github.io/miceDRF/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"MICE and Distributional Random Forest for Imputation","text":"use miceDRF research, please cite following work: https://doi.org/10.48550/arXiv.2507.11297","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/Iscore.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculates score for one imputation function ‚Äî Iscore","title":"Calculates score for one imputation function ‚Äî Iscore","text":"Calculates score one imputation function","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/Iscore.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates score for one imputation function ‚Äî Iscore","text":"","code":"Iscore(   X,   X_imp,   multiple = TRUE,   N = 50,   imputation_func,   max_length = NULL,   skip_if_needed = TRUE,   scale = FALSE )"},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/Iscore.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculates score for one imputation function ‚Äî Iscore","text":"X data containing missing values denoted NA's X_imp imputed dataset. multiple logical indicating whether provided imputation method multiple imputation approach (.e. generates different values impute call). Default TRUE. Note multiple equals FALSE, N automatically set 1. N numeric value. Number samples imputation distribution H. Default 50. imputation_func function imputes data max_length Maximum number variables \\(X_j\\) consider, can speed code. Default NULL meaning columns taken consideration. skip_if_needed logical, indicating whether observations skipped obtain complete columns scoring. FALSE, NA returned column observed variable training. scale logica. TRUE, variable scaled score.","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/Iscore.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculates score for one imputation function ‚Äî Iscore","text":"numerical value denoting weighted Imputation Score obtained provided imputation function table scores weights calculated particular columns.","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/Iscore.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculates score for one imputation function ‚Äî Iscore","text":"","code":"set.seed(111) X <- matrix(rnorm(1000), nrow = 100) X[runif(1000) < 0.4] <- NA imputation_func <- miceDRF:::create_mice_imputation(\"pmm\") X_imp <- imputation_func(X)  miceDRF::Iscore(X, X_imp, N = 50, imputation_func = imputation_func) #> No complete variables for training column 1. Skipping some observations. #> No complete variables for training column 3. Skipping some observations. #> No complete variables for training column 8. Skipping some observations. #> No complete variables for training column 10. Skipping some observations. #> No complete variables for training column 5. Skipping some observations. #> No complete variables for training column 6. Skipping some observations. #> No complete variables for training column 7. Skipping some observations. #> No complete variables for training column 4. Skipping some observations. #> No complete variables for training column 9. Skipping some observations. #> No complete variables for training column 2. Skipping some observations. #> [1] 0.5583584 #> attr(,\"dat\") #>     column_id weight     score n_columns_used #> V1          1 0.2499 0.5616408              1 #> V3          3 0.2491 0.4377913              1 #> V8          8 0.2475 0.5055475              1 #> V10        10 0.2475 0.5922144              1 #> V5          5 0.2464 0.6850586              1 #> V6          6 0.2436 0.5006411              1 #> V7          7 0.2379 0.6925815              1 #> V4          4 0.2331 0.5294290              1 #> V9          9 0.2331 0.5369845              1 #> V2          2 0.2244 0.5429367              1  imputation_func <- miceDRF:::create_mice_imputation(\"mean\") X_imp <- imputation_func(X)  miceDRF::Iscore(X, X_imp, N = 50, imputation_func = imputation_func) #> No complete variables for training column 1. Skipping some observations. #> No complete variables for training column 3. Skipping some observations. #> No complete variables for training column 8. Skipping some observations. #> No complete variables for training column 10. Skipping some observations. #> No complete variables for training column 5. Skipping some observations. #> No complete variables for training column 6. Skipping some observations. #> No complete variables for training column 7. Skipping some observations. #> No complete variables for training column 4. Skipping some observations. #> No complete variables for training column 9. Skipping some observations. #> No complete variables for training column 2. Skipping some observations. #> [1] 0.7652515 #> attr(,\"dat\") #>     column_id weight     score n_columns_used #> V1          1 0.2499 0.7787504              1 #> V3          3 0.2491 0.6142445              1 #> V8          8 0.2475 0.7015580              1 #> V10        10 0.2475 0.7621273              1 #> V5          5 0.2464 0.9875052              1 #> V6          6 0.2436 0.6425266              1 #> V7          7 0.2379 0.9592499              1 #> V4          4 0.2331 0.7665391              1 #> V9          9 0.2331 0.7250410              1 #> V2          2 0.2244 0.7154879              1  miceDRF::Iscore(X, X_imp, N = 50, imputation_func = imputation_func, multiple = FALSE) #> No complete variables for training column 1. Skipping some observations. #> No complete variables for training column 3. Skipping some observations. #> No complete variables for training column 8. Skipping some observations. #> No complete variables for training column 10. Skipping some observations. #> No complete variables for training column 5. Skipping some observations. #> No complete variables for training column 6. Skipping some observations. #> No complete variables for training column 7. Skipping some observations. #> No complete variables for training column 4. Skipping some observations. #> No complete variables for training column 9. Skipping some observations. #> No complete variables for training column 2. Skipping some observations. #> [1] 0.7652515 #> attr(,\"dat\") #>     column_id weight     score n_columns_used #> V1          1 0.2499 0.7787504              1 #> V3          3 0.2491 0.6142445              1 #> V8          8 0.2475 0.7015580              1 #> V10        10 0.2475 0.7621273              1 #> V5          5 0.2464 0.9875052              1 #> V6          6 0.2436 0.6425266              1 #> V7          7 0.2379 0.9592499              1 #> V4          4 0.2331 0.7665391              1 #> V9          9 0.2331 0.7250410              1 #> V2          2 0.2244 0.7154879              1  # zero imputation X <- matrix(rnorm(1000), nrow = 100) X[c(runif(1000) < 0.3)] <- NA imputation_func <- function(X) {X[is.na(X)] <- 0; X} X_imp <- imputation_func(X)  Iscore(X, X_imp, N = 50, imputation_func = imputation_func, multiple = FALSE) #> No complete variables for training column 5. Skipping some observations. #> No complete variables for training column 7. Skipping some observations. #> No complete variables for training column 2. Skipping some observations. #> No complete variables for training column 4. Skipping some observations. #> No complete variables for training column 8. Skipping some observations. #> No complete variables for training column 6. Skipping some observations. #> No complete variables for training column 1. Skipping some observations. #> No complete variables for training column 10. Skipping some observations. #> No complete variables for training column 3. Skipping some observations. #> No complete variables for training column 9. Skipping some observations. #> [1] 0.8265311 #> attr(,\"dat\") #>     column_id weight     score n_columns_used #> V5          5 0.2400 0.7023632              1 #> V7          7 0.2275 0.8767438              1 #> V2          2 0.2211 0.8043624              1 #> V4          4 0.2100 0.9224779              1 #> V8          8 0.2100 0.8895373              1 #> V6          6 0.2059 0.7644872              1 #> V1          1 0.1971 0.7896345              1 #> V10        10 0.1971 0.8515953              1 #> V3          3 0.1924 0.8454487              1 #> V9          9 0.1659 0.8347622              1"},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/Iscore_cat.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculates score for a single imputation function ‚Äî Iscore_cat","title":"Calculates score for a single imputation function ‚Äî Iscore_cat","text":"Calculates score single imputation function","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/Iscore_cat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates score for a single imputation function ‚Äî Iscore_cat","text":"","code":"Iscore_cat(   X,   X_imp,   imputation_func,   factor_vars = TRUE,   multiple = TRUE,   N = 50,   max_length = NULL,   skip_if_needed = TRUE )"},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/Iscore_cat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculates score for a single imputation function ‚Äî Iscore_cat","text":"X data containing missing values denoted NA's X_imp imputed dataset. imputation_func function imputes data factor_vars logical value indicating whether imputation performed factors. FALSE, variables factors converted numeric values. multiple logical indicating whether provided imputation method multiple imputation approach (.e. generates different values impute call). Default TRUE. Note multiple equals FALSE, N automatically set 1. N numeric value. Number samples imputation distribution H. Default 50. max_length Maximum number variables \\(X_j\\) consider, can speed code. Default NULL meaning columns taken consideration. skip_if_needed logical, indicating whether observations skipped obtain complete columns scoring. FALSE, NA returned column observed variable training.","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/Iscore_cat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculates score for a single imputation function ‚Äî Iscore_cat","text":"numerical value denoting weighted Imputation Score obtained provided imputation function table scores weights calculated particular columns.","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/Iscore_cat.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculates score for a single imputation function ‚Äî Iscore_cat","text":"categorical variables stored factors. need additional conversion data (example one-hot encoding) imputation, please, implement everything within imputation_func parameter. can use miceDRF:::onehot_to_factor miceDRF:::factor_to_onehot functions.","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/Iscore_cat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculates score for a single imputation function ‚Äî Iscore_cat","text":"","code":"set.seed(123) X <- matrix(rnorm(500), nrow = 100) X <- cbind(X, factor(sample(1:5, 100, replace = TRUE), levels = 1:5)) X[runif(600) < 0.2] <- NA X <- cbind(X, factor(sample(1:2, 100, replace = TRUE), levels = 1:2)) X <- as.data.frame(X) X[[\"V6\"]] <- factor(X[[\"V6\"]], levels = 1:5) X[[\"V7\"]] <- factor(X[[\"V7\"]], levels = 1:2) X[[\"V8\"]] <- rnorm(100) imputation_func <- miceDRF:::create_mice_imputation(\"cart\") X_imp <- imputation_func(X)  Iscore_cat(X, X_imp, imputation_func, factor_vars = FALSE) #> [1] 0.6935389 #> attr(,\"dat\") #>    column_id weight     score n_columns_used #> V1         1 0.1971 0.6819397              2 #> V5         5 0.1924 0.6718325              2 #> V3         3 0.1600 0.7061233              2 #> V6         6 0.1539 0.6258925              2 #> V2         2 0.1476 0.7203252              2 #> V4         4 0.1275 0.7790775              2"},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/Iscores_compare.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculates IScores for multiple imputation functions ‚Äî Iscores_compare","title":"Calculates IScores for multiple imputation functions ‚Äî Iscores_compare","text":"Calculates IScores multiple imputation functions","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/Iscores_compare.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates IScores for multiple imputation functions ‚Äî Iscores_compare","text":"","code":"Iscores_compare(   X,   imputation_list,   methods = NULL,   N = 50,   max_length = NULL,   skip_if_needed = TRUE )"},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/Iscores_compare.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculates IScores for multiple imputation functions ‚Äî Iscores_compare","text":"imputation_list list imputation functions methods character vector names methods imputation_list. can NULL, function attempt get names imputation_list object.","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/Iscores_compare.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculates IScores for multiple imputation functions ‚Äî Iscores_compare","text":"vector IScores provided methods","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/Iscores_compare.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculates IScores for multiple imputation functions ‚Äî Iscores_compare","text":"","code":"set.seed(111) X <- matrix(rnorm(1000), nrow = 100) X[runif(1000) < 0.4] <- NA  methods <- c(\"pmm\", \"cart\", \"sample\", \"norm.nob\", \"DRF\") imputation_list <- create_mice_imputations(methods)  Iscores_compare(X, imputation_list) #> [1] \"Calculating score for method: pmm\" #> No complete variables for training column 1. Skipping some observations. #> No complete variables for training column 3. Skipping some observations. #> No complete variables for training column 8. Skipping some observations. #> No complete variables for training column 10. Skipping some observations. #> No complete variables for training column 5. Skipping some observations. #> No complete variables for training column 6. Skipping some observations. #> No complete variables for training column 7. Skipping some observations. #> No complete variables for training column 4. Skipping some observations. #> No complete variables for training column 9. Skipping some observations. #> No complete variables for training column 2. Skipping some observations. #> [1] \"Calculating score for method: cart\" #> No complete variables for training column 1. Skipping some observations. #> No complete variables for training column 3. Skipping some observations. #> No complete variables for training column 8. Skipping some observations. #> No complete variables for training column 10. Skipping some observations. #> No complete variables for training column 5. Skipping some observations. #> No complete variables for training column 6. Skipping some observations. #> No complete variables for training column 7. Skipping some observations. #> No complete variables for training column 4. Skipping some observations. #> No complete variables for training column 9. Skipping some observations. #> No complete variables for training column 2. Skipping some observations. #> [1] \"Calculating score for method: sample\" #> No complete variables for training column 1. Skipping some observations. #> No complete variables for training column 3. Skipping some observations. #> No complete variables for training column 8. Skipping some observations. #> No complete variables for training column 10. Skipping some observations. #> No complete variables for training column 5. Skipping some observations. #> No complete variables for training column 6. Skipping some observations. #> No complete variables for training column 7. Skipping some observations. #> No complete variables for training column 4. Skipping some observations. #> No complete variables for training column 9. Skipping some observations. #> No complete variables for training column 2. Skipping some observations. #> [1] \"Calculating score for method: norm.nob\" #> No complete variables for training column 1. Skipping some observations. #> No complete variables for training column 3. Skipping some observations. #> No complete variables for training column 8. Skipping some observations. #> No complete variables for training column 10. Skipping some observations. #> No complete variables for training column 5. Skipping some observations. #> No complete variables for training column 6. Skipping some observations. #> No complete variables for training column 7. Skipping some observations. #> No complete variables for training column 4. Skipping some observations. #> No complete variables for training column 9. Skipping some observations. #> No complete variables for training column 2. Skipping some observations. #> [1] \"Calculating score for method: DRF\" #> No complete variables for training column 1. Skipping some observations. #> No complete variables for training column 3. Skipping some observations. #> No complete variables for training column 8. Skipping some observations. #> No complete variables for training column 10. Skipping some observations. #> No complete variables for training column 5. Skipping some observations. #> No complete variables for training column 6. Skipping some observations. #> No complete variables for training column 7. Skipping some observations. #> No complete variables for training column 4. Skipping some observations. #> No complete variables for training column 9. Skipping some observations. #> No complete variables for training column 2. Skipping some observations. #>    sample  norm.nob       pmm      cart       DRF  #> 0.5485229 0.5488967 0.5583584 0.5797292 0.5963409"},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/create_mice_imputation.html","id":null,"dir":"Reference","previous_headings":"","what":"Very internal function for getting mice methods ‚Äî create_mice_imputation","title":"Very internal function for getting mice methods ‚Äî create_mice_imputation","text":"internal function getting mice methods","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/create_mice_imputation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Very internal function for getting mice methods ‚Äî create_mice_imputation","text":"","code":"create_mice_imputation(method)"},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/create_mice_imputation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Very internal function for getting mice methods ‚Äî create_mice_imputation","text":"","code":"methods <- \"pmm\" imputation_funcs <- create_mice_imputations(methods)"},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/create_mice_imputations.html","id":null,"dir":"Reference","previous_headings":"","what":"A function creating list of mice imputation functions ‚Äî create_mice_imputations","title":"A function creating list of mice imputation functions ‚Äî create_mice_imputations","text":"function creating list mice imputation functions","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/create_mice_imputations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A function creating list of mice imputation functions ‚Äî create_mice_imputations","text":"","code":"create_mice_imputations(methods)"},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/create_mice_imputations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A function creating list of mice imputation functions ‚Äî create_mice_imputations","text":"methods character vector names mice methods","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/create_mice_imputations.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A function creating list of mice imputation functions ‚Äî create_mice_imputations","text":"","code":"methods <- c(\"pmm\", \"cart\", \"sample\", \"norm.nob\", \"DRF\") reate_mice_imputations(methods) #> Error in reate_mice_imputations(methods): could not find function \"reate_mice_imputations\""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/do_one_hot.html","id":null,"dir":"Reference","previous_headings":"","what":"One hot encoding A supplementarty function for one-hot encoding ‚Äî do_one_hot","title":"One hot encoding A supplementarty function for one-hot encoding ‚Äî do_one_hot","text":"One hot encoding supplementarty function one-hot encoding","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/do_one_hot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"One hot encoding A supplementarty function for one-hot encoding ‚Äî do_one_hot","text":"","code":"do_one_hot(vec)"},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/do_one_hot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"One hot encoding A supplementarty function for one-hot encoding ‚Äî do_one_hot","text":"vec factor vector encoded","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/energy_dist.html","id":null,"dir":"Reference","previous_headings":"","what":"Energy distance ‚Äî energy_dist","title":"Energy distance ‚Äî energy_dist","text":"function wrapper energy distance calculating. details see eqdist.e.","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/energy_dist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Energy distance ‚Äî energy_dist","text":"","code":"energy_dist(X, X_imp)"},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/energy_dist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Energy distance ‚Äî energy_dist","text":"X complete original dataset X_imp imputed dataset","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/energy_dist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Energy distance ‚Äî energy_dist","text":"","code":"X <- matrix(rnorm(1000), nrow = 100) X_imp <- matrix(rnorm(1000), nrow = 100) energy_dist(X, X_imp) #> E-statistic  #>    2.856983"},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/factor_to_numeric.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal function for changing factors to numerical A supplementarty function for data management ‚Äî factor_to_numeric","title":"Internal function for changing factors to numerical A supplementarty function for data management ‚Äî factor_to_numeric","text":"Internal function changing factors numerical supplementarty function data management","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/factor_to_numeric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal function for changing factors to numerical A supplementarty function for data management ‚Äî factor_to_numeric","text":"","code":"factor_to_numeric(factor_col)"},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/factor_to_numeric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal function for changing factors to numerical A supplementarty function for data management ‚Äî factor_to_numeric","text":"factor_col factor column","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/factor_to_onehot.html","id":null,"dir":"Reference","previous_headings":"","what":"One hot encoding A supplementarty function for one-hot encoding ‚Äî factor_to_onehot","title":"One hot encoding A supplementarty function for one-hot encoding ‚Äî factor_to_onehot","text":"One hot encoding supplementarty function one-hot encoding","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/factor_to_onehot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"One hot encoding A supplementarty function for one-hot encoding ‚Äî factor_to_onehot","text":"","code":"factor_to_onehot(dat)"},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/factor_to_onehot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"One hot encoding A supplementarty function for one-hot encoding ‚Äî factor_to_onehot","text":"dat data containinig factor numeric columns.","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/impute_mice_drf.html","id":null,"dir":"Reference","previous_headings":"","what":"mice DRF (Distributional Random Forest) ‚Äî impute_mice_drf","title":"mice DRF (Distributional Random Forest) ‚Äî impute_mice_drf","text":"function performs imputation using MICE Distributional Random Forest","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/impute_mice_drf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"mice DRF (Distributional Random Forest) ‚Äî impute_mice_drf","text":"","code":"impute_mice_drf(missdf, printFlag = FALSE, m = 1, ...)"},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/impute_mice_drf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"mice DRF (Distributional Random Forest) ‚Äî impute_mice_drf","text":"missdf incomplete dataset missing values denoted NA's printFlag logical, indicating whether silent computations performed. Default FALSE. m number imputed datasets generate ... used compatibility mice package.","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/impute_mice_drf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"mice DRF (Distributional Random Forest) ‚Äî impute_mice_drf","text":"completed dataset","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/impute_mice_drf.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"mice DRF (Distributional Random Forest) ‚Äî impute_mice_drf","text":"method described detail : N√§f, J., Scornet, E., & Josse, J. (2024). good imputation MAR missingness?. arXiv. https://arxiv.org/abs/2403.19196 based : Cevid, D., Michel, L., N√§f, J., Meinshausen, N., B¬® uhlmann, P. (2022). Distributional random forests: Heterogeneity adjustment multivariate distributional regression. Journal Machine Learning Research, 23(333):1‚Äì79.","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/impute_mice_drf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"mice DRF (Distributional Random Forest) ‚Äî impute_mice_drf","text":"","code":"X <- matrix(rnorm(1000), nrow = 100) X[c(runif(700), rep(1, 300)) < 0.3] <- NA impute_mice_drf(X, printFlag = TRUE) #>  #>  iter imp variable #>   1   1  V1  V2  V3  V4  V5  V6  V7 #>   2   1  V1  V2  V3  V4  V5  V6  V7 #>   3   1  V1  V2  V3  V4  V5  V6  V7 #>   4   1  V1  V2  V3  V4  V5  V6  V7 #>   5   1  V1  V2  V3  V4  V5  V6  V7 #>              V1           V2           V3          V4           V5           V6 #> 1   -0.93743468  0.149229512  2.530880883  0.19214351  0.395176361 -0.957751046 #> 2    1.28688164 -1.146127540 -1.287311583 -0.10554037  0.486490770  1.600943510 #> 3    0.33672624  0.856525578  0.586099490  1.38908483  0.561637619 -0.487547486 #> 4    0.71940633 -0.086366504  0.311441256  2.17571376 -0.084825132  0.627354263 #> 5    0.61925455 -1.106474590  0.683950483 -0.19591214 -0.724563506 -0.905171562 #> 6   -0.22233623  0.159653625  0.087854435 -1.34776032  0.003043269 -0.225451218 #> 7    0.53432137 -1.977855558  2.054933912  0.34677776  0.539804286 -0.334988147 #> 8    1.07173292  0.783822843 -1.209440108 -0.12579932 -1.129071305  0.096973976 #> 9    1.68438030  0.816012249 -0.663780747 -1.52235366 -0.173587690  1.423401455 #> 10  -0.08384108 -1.109778336  0.809810155  0.45333126 -0.927792529 -1.362817183 #> 11   0.65953668 -0.502129000  0.290448039  0.80328409 -0.338561004 -0.051245357 #> 12   0.48015134  0.805096892 -0.528577183 -0.65536496 -1.129071305 -0.984234083 #> 13  -0.50858149 -0.068283211 -1.313754437  1.57886129 -0.907792905 -1.218266313 #> 14  -0.93743468  0.816012249 -1.152557256  2.78317685 -0.919966926  0.788521753 #> 15   0.84649723 -0.042339989 -0.556984384  0.69659032 -0.305445939 -0.701459961 #> 16   1.68438030 -0.319740990 -0.849637404 -1.12660654 -1.129071305  0.641974382 #> 17   1.68438030  0.880856591 -0.763310495 -0.59774480  0.314597297 -0.225451218 #> 18   1.62392791 -0.363584441 -0.595445676  0.61809941 -0.049874742 -1.166747818 #> 19  -1.64092832  0.189130116 -1.000836479  0.50318026  0.268012627 -0.470968884 #> 20   1.50413123 -0.374912346 -0.818241039 -1.98948653  1.962265080 -0.327861857 #> 21   0.32989616  1.806353957 -1.209440108 -2.14723957  0.003043269  1.683935216 #> 22  -0.48037689  1.499820973 -0.721250277 -2.14723957  1.180592313  0.860888932 #> 23   0.59938719 -0.445191426  1.210192592  0.41692781 -0.104474175 -0.209798099 #> 24   0.08179674  0.684289690  1.071719182  0.47635200  0.696815400  1.568387123 #> 25  -0.29490872  0.840043419 -0.239392802  0.44092982  1.826597003 -1.362817183 #> 26  -0.16938226  0.684289690  0.086370137  0.31919368  0.544346904  0.453590809 #> 27   0.41081111 -0.997468040  0.287424477 -0.59774480  0.060687493 -1.083275584 #> 28   0.18539057 -1.371366652  0.586099490  0.44092982 -0.173587690  0.255739498 #> 29  -0.29638099  1.431845075  0.961140017  1.68288885  1.027789907  0.206072394 #> 30  -0.67878560 -0.229365189  0.287424477  0.31271096 -0.173587690 -0.078704194 #> 31   0.15378347  0.304539693  1.803838389 -0.57096675 -0.724563506 -1.809213595 #> 32   0.08179674 -0.475148778 -1.632360331  0.61809941 -0.853365317  1.600943510 #> 33   0.67392158 -0.462163972 -1.251852207  1.36075282  1.278136973  0.815759029 #> 34   0.31843283 -1.747663966  0.383039128 -0.12796151 -0.712990916 -0.225451218 #> 35  -0.32921809  0.288981847  1.275849074  0.08128212  0.696815400 -0.643478427 #> 36  -0.79045780 -1.977855558  1.396928098  0.36812613 -1.766545941 -0.984234083 #> 37  -1.50453174  0.001271804 -1.000836479  0.96363707 -1.087288977  1.600943510 #> 38   1.04891102 -0.203272992 -0.240917605 -0.62341367 -0.798781064 -0.984234083 #> 39   0.49203996 -0.778751273  0.289227688  0.29263250 -1.129071305  0.096973976 #> 40  -0.94801098  1.499820973 -0.484251474 -0.59651797  0.625520585 -0.439396920 #> 41   0.61925455  0.288981847  0.821819472 -0.62341367  0.062812424 -0.957751046 #> 42  -0.13845867  0.242247923 -0.317028901  0.34688511  1.756613966 -0.327861857 #> 43   1.68438030  0.573436490 -1.171796995  1.06741731  0.632786540 -0.439396920 #> 44  -1.10657121  0.001271804 -0.057414156  0.45333126 -0.556727565 -1.414387055 #> 45   0.59261609 -0.032502035 -1.632360331  0.26037050  1.080828209  0.991551586 #> 46   0.81747763 -0.032502035  0.290448039 -0.65536496  0.142185519 -0.126156858 #> 47  -0.09795342 -0.765246153  0.367137188 -1.38001451  1.041690149 -0.225451218 #> 48  -0.73473107  0.203872954  0.903329722 -1.15352061 -0.718046731  1.577553937 #> 49   0.31626073 -0.363584441 -0.008721016 -1.11679059 -1.208281338 -1.638909680 #> 50   1.62392791 -1.424211154  0.625236835  0.53954868 -0.893915325 -0.327861857 #> 51  -0.33298396  0.840043419 -0.311908313  0.38225069  0.923698265  0.304557069 #> 52  -1.49429674 -1.146127540 -0.616206522  0.36812613  0.440262312 -0.643478427 #> 53  -0.61632817  1.897455385 -1.181282487  1.96181572  0.842274667 -0.242346951 #> 54   1.46401623 -0.032502035  1.583152058  0.54053006 -0.365682535 -0.122004019 #> 55   0.59261609  0.632021417  1.275849074  0.80328409  0.632786540  1.300319602 #> 56   0.32636532 -1.915176469 -0.519467400 -0.65536496 -0.006167482 -0.594756957 #> 57  -0.18047033  1.499820973  0.683950483 -0.19005189 -1.521375988 -1.414387055 #> 58  -0.08503526 -0.778751273 -0.721250277  1.58487726 -1.485946957  0.353627597 #> 59   1.46401623  1.775738591 -0.616206522  0.44092982 -0.488356802 -1.115904656 #> 60  -0.16991391  0.029503727  1.864039764 -0.22351834  0.511616545  0.897685576 #> 61  -0.16991391  0.841352749  0.809810155 -0.91068045 -1.844161498  1.496522312 #> 62  -1.10657121 -0.769807637 -0.055972957 -1.75691894 -0.377536227 -0.225451218 #> 63   0.06363471  1.361406606  0.421569407 -1.12660654  0.588013747  1.496522312 #> 64  -1.50453174 -0.507869156 -0.055972957  0.36812613  0.054892200  0.096973976 #> 65   0.48015134 -0.363584441 -0.016285264  0.45333126 -1.233205874 -0.968150285 #> 66  -0.71378725  0.816012249  1.263480871  0.05099371  0.062812424 -1.240127089 #> 67   0.16192197  1.126586563 -0.026260625  2.04728356  1.962265080 -0.015711382 #> 68  -0.01300787 -0.461012089  1.028074343 -1.11679059 -0.919966926  1.577553937 #> 69   0.55182611  0.826341246 -1.237613524 -0.06802552  0.054892200 -0.993431613 #> 70   0.51475024 -0.633563361  1.005198805  1.38410737 -0.264603566  0.040302731 #> 71  -0.56080274  0.431235347 -0.721250277 -2.14723957  1.125422777 -0.984234083 #> 72  -0.08384108  0.841352749  0.809810155 -1.15352061 -0.919966926 -0.957751046 #> 73  -0.73473107  0.433857872  1.071719182  1.68288885 -0.907792905 -0.218661708 #> 74   0.54195351 -0.363584441 -1.632360331 -0.65536496 -0.338561004  1.600943510 #> 75  -0.43463584  0.868971862 -1.237613524  0.26260780 -0.839033295  0.007330823 #> 76   0.51475024 -0.934379416  0.679418867  1.06741731  2.297226745 -0.844230684 #> 77  -0.09795342 -1.146127540  0.961140017  0.51721535 -0.508616697 -0.957751046 #> 78   0.19385428 -0.445191426  0.891146892  1.55314170  0.842274667 -0.010196613 #> 79  -1.44086338 -0.752133229 -0.965649945  0.61809941 -2.843903969 -0.078704194 #> 80  -1.05923883  1.738203319 -0.616206522 -0.22351834  0.384470742 -1.722270961 #> 81   0.33452432 -0.445191426 -0.965649945  1.06741731  0.810723067  1.055670041 #> 82  -1.42880222  0.548243591 -1.000836479  0.29263250 -1.218317236 -0.820075440 #> 83   0.51682033  0.026341096  1.193984263 -1.11679059 -0.414183224 -0.957751046 #> 84  -0.66210553  2.093788956  1.143615173 -2.14723957  0.610201872 -0.820075440 #> 85   1.37974265  1.460823258 -0.240917605  0.69659032  0.148788755 -0.541106012 #> 86   1.41432895  0.613670714  1.864039764  2.04728356  0.832068087  0.412825400 #> 87   0.31626073  0.431235347 -0.798780780 -0.09108705 -0.395695307  0.127049822 #> 88   0.11270992 -0.908734798 -0.453234242 -1.75691894 -0.724563506 -1.460289695 #> 89  -0.90786118  0.281453856 -0.519467400  0.29263250 -0.511453632 -0.808852822 #> 90  -0.09795342  0.000855028  0.644238937 -0.88801639  1.426383031  1.211711761 #> 91   0.05917832 -0.374912346 -1.764873467  0.29263250  0.371518183  1.895972824 #> 92  -0.66210553  0.360298601 -0.484251474  0.26037050  0.625520585 -1.079315188 #> 93   0.11337711 -1.033702590  0.311441256  1.58487726 -0.712990916 -0.844230684 #> 94   0.53432137  0.288981847 -0.889790415 -1.34776032 -0.414183224 -0.982286551 #> 95   0.31626073 -0.965746254  0.287424477 -0.76351032  0.314597297  0.096973976 #> 96   0.49203996  0.684289690  0.374446341  0.26037050 -0.365682535  1.228311223 #> 97  -0.99482366 -0.374912346 -1.181282487 -0.62341367 -1.485946957 -0.225451218 #> 98   0.84649723  1.102187440  1.263480871  1.38908483  1.480345125  0.304557069 #> 99  -0.85326948  1.350913153  0.311441256  0.27331446  0.337505528 -1.079315188 #> 100 -0.18047033 -0.153170023 -1.209440108  0.34777868 -0.769066855 -0.227307438 #>              V7          V8           V9          V10 #> 1   -0.20282364 -0.77001802  0.248688464  0.573087733 #> 2    0.92690813  0.30954407 -0.660340352  0.563727132 #> 3   -1.81580070 -0.79547942  1.404557699  1.722887443 #> 4   -0.20964575  1.93111704 -1.087238691 -0.446319043 #> 5    0.29925337  0.56053724  0.495159038  0.464209238 #> 6    1.05277374 -1.74630153  0.035439877  0.683688618 #> 7    1.22173093 -0.56402757 -0.772153598  0.303492997 #> 8   -0.20471146  0.91004076  0.358623199  0.146856901 #> 9    2.40900905  1.46205510 -0.070991884 -0.169666635 #> 10  -1.04436575 -0.04213147 -1.870125598  0.454430816 #> 11   0.19889976  0.01176334  0.330915403 -0.196930126 #> 12   1.19998051 -0.17612720  0.000520376  0.148387906 #> 13   0.40412185 -1.16665165 -1.223059834  0.094618250 #> 14   1.22173093 -0.70085795 -0.950131027 -0.459623227 #> 15   0.47008251  1.01817614 -0.543937987 -1.332928624 #> 16   0.13889380  0.76492355 -0.818050574 -0.272514422 #> 17  -0.68187057 -1.33026427 -0.568923788  0.275951805 #> 18   1.97529191  1.38094563  0.905392199  0.600672707 #> 19  -0.90029014 -0.57383538 -0.079936781 -2.014221834 #> 20  -0.96860936 -0.26382308 -0.395955917  1.584627484 #> 21  -1.52864479  0.49313921 -0.497565309  0.840870445 #> 22  -1.67431865 -0.66141816  0.104889868  0.882871454 #> 23   1.05277374 -1.22201315 -1.280133368  0.763517484 #> 24   2.19306193 -0.68049208 -0.779743945  0.874873060 #> 25  -1.78804246  0.37937841 -1.877766196  0.260855937 #> 26  -0.34571015 -0.22556627  0.929537894  1.223767364 #> 27  -0.30607712 -1.09041207 -1.640011935  1.160492569 #> 28   0.76684448 -0.04325630 -0.694588214 -0.166991823 #> 29  -1.37420121 -0.44388440  0.346611582 -1.498935503 #> 30   0.76501476  0.28656121 -0.316884063 -0.362028451 #> 31   0.47008251 -1.54211230  0.474813814 -1.004400808 #> 32  -0.34571015 -0.38520177  1.353343832  1.059126452 #> 33  -0.96860936 -0.66392604  2.282476280 -0.017100474 #> 34  -0.40484620 -1.33308583  1.176133456  0.578062231 #> 35  -0.23947810 -0.97117698 -0.463990133 -1.334739539 #> 36   1.09002474 -0.91219310  1.475873010  0.800148659 #> 37  -0.69060800 -0.06643996 -1.103792987 -0.999821364 #> 38  -0.89956319 -0.42202678 -2.387478223 -1.232616814 #> 39   1.22173093  2.24627009 -1.392164235 -0.668775151 #> 40   1.05277374  0.75113000 -0.049269509  0.164242234 #> 41  -0.91471058  0.51734417 -0.901170605 -0.170597752 #> 42   0.03338432 -0.63640359  1.345262778  0.115563319 #> 43   0.49537239 -0.56176320  0.111869791 -0.745606869 #> 44   1.05277374  1.01687864 -1.534485001 -1.415590033 #> 45   0.59408920  0.17641685  0.870150893 -0.379915961 #> 46   1.18442064  0.84149019  1.218354938 -0.165558359 #> 47  -0.30507282 -1.42105069 -0.584779870  0.637425749 #> 48   0.41207011 -0.51094604  0.692002648 -0.468060769 #> 49  -0.89119837  2.41114714  0.827685653  0.061739673 #> 50  -0.30571240  0.59417122  1.856614116 -0.341749845 #> 51  -1.74479100 -0.77035888 -0.321293505  2.129766807 #> 52   1.05277374 -1.31785488 -1.371266991  0.750312477 #> 53   1.05277374 -1.12439288  1.654672389  2.045294957 #> 54   0.32597526  0.08040567 -0.668042403 -0.713988946 #> 55   0.63794559  0.51718140 -0.575315441  0.009999535 #> 56  -0.86103932 -0.87059622 -0.415124833 -2.218131324 #> 57   1.97529191  2.57058248  1.435314204  0.570258001 #> 58  -1.04448231 -0.46344343 -2.797881897 -0.198938776 #> 59   1.40237230  2.02476307 -0.126725112 -0.458510619 #> 60   2.53432069 -0.97344825 -0.913518615 -0.031454180 #> 61  -0.49949678 -1.03490760 -1.151527020  0.140154756 #> 62   2.40900905  1.40533448 -0.170082602 -1.507572162 #> 63  -0.87394230  0.51540196 -1.025576521  1.699335576 #> 64  -1.78804246  0.91935697 -1.180125254  0.646511570 #> 65  -1.85757154 -1.00327729  0.850880560 -1.932508910 #> 66   1.90685660  1.73939743 -0.880418845  0.270316192 #> 67  -1.67431865 -0.56043291  0.137347957  0.440567693 #> 68   1.27963302 -0.38922835  0.996626751 -0.728270656 #> 69   0.23405077  1.09218635 -1.267459021  0.162328177 #> 70   0.16754793  0.32346208  0.630351455 -0.647826703 #> 71   0.23816952  0.04092342 -0.611529129  0.370486324 #> 72   0.84227560 -0.32729339 -1.497865064 -0.492308415 #> 73   1.40237230  1.45042234  0.495485524 -0.410927094 #> 74   0.13889380  0.29076547  1.554843104 -0.601084132 #> 75  -0.19563060  1.08086473  1.173189656 -0.134675523 #> 76   1.40237230  1.17676933  0.705603666 -0.390111389 #> 77  -1.52864479 -2.38829461  0.037776992 -0.370976748 #> 78   0.04793931 -0.53824143 -1.334058852  1.575259511 #> 79   0.29925337 -0.98837904  0.038252262 -0.436669104 #> 80  -1.52864479 -1.30696308 -0.967607652  1.827817903 #> 81  -0.11338919 -1.10221985 -0.384389521 -0.685294239 #> 82  -1.06213683  0.23234698  0.182817934 -0.773022043 #> 83  -1.81580070 -0.44724503  1.585191098  0.420134208 #> 84  -0.86103932 -1.39506650 -0.536568292  1.171604762 #> 85   0.47008251 -0.46326196  0.096855966 -1.087096180 #> 86   0.72651143 -0.24928436  0.216811244 -1.615103757 #> 87   0.40452524  1.86067942  0.078917970 -0.198967716 #> 88  -0.27695751 -0.76574729  0.220997015 -2.080669907 #> 89  -0.86790942  0.53452681 -0.173640350 -0.447074699 #> 90   0.35460765 -0.06728061  1.375723150  0.241725490 #> 91  -1.49531853  0.93887656  0.822393098  0.387176191 #> 92   0.83989485 -0.52969623 -0.207818582  0.153468424 #> 93  -1.48314874  0.89960753  0.605831206  0.588469182 #> 94  -0.49949678 -0.08077534 -1.165042289  0.296213085 #> 95  -0.26183760  1.06494146  0.093231009 -0.044539142 #> 96   1.34025411 -0.02863485 -1.506688813 -1.388181846 #> 97  -0.01073796 -1.47751220  0.411238970  0.696735836 #> 98   0.63794559  1.73050262 -1.061507161  0.941216768 #> 99   0.13114613  0.72451310 -0.014949790 -0.907448029 #> 100 -0.43597085 -1.04909401  0.661419697 -1.795962050"},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/mice.impute.DRF.html","id":null,"dir":"Reference","previous_headings":"","what":"mice DRF (Distributional Random Forest) ‚Äî mice.impute.DRF","title":"mice DRF (Distributional Random Forest) ‚Äî mice.impute.DRF","text":"function performs imputation using MICE Distributional Random Forest","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/mice.impute.DRF.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"mice DRF (Distributional Random Forest) ‚Äî mice.impute.DRF","text":"","code":"mice.impute.DRF(   y,   ry,   x,   wy = NULL,   min.node.size = 1,   num.features = 10,   num.trees = 10,   ... )"},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/mice.impute.DRF.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"mice DRF (Distributional Random Forest) ‚Äî mice.impute.DRF","text":"y words, words... ry words, words... x words, words... wy words, words... min.node.size words, words... num.features words, words... num.trees words, words...","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/mice.impute.DRF.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"mice DRF (Distributional Random Forest) ‚Äî mice.impute.DRF","text":"method described detail : N√§f, J., Scornet, E., & Josse, J. (2024). good imputation MAR missingness?. arXiv. https://arxiv.org/abs/2403.19196 based : Cevid, D., Michel, L., N√§f, J., Meinshausen, N., B¬® uhlmann, P. (2022). Distributional random forests: Heterogeneity adjustment multivariate distributional regression. Journal Machine Learning Research, 23(333):1‚Äì79.","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/onehot_to_factor.html","id":null,"dir":"Reference","previous_headings":"","what":"One hot encoding A supplementarty function for one-hot encoding ‚Äî onehot_to_factor","title":"One hot encoding A supplementarty function for one-hot encoding ‚Äî onehot_to_factor","text":"One hot encoding supplementarty function one-hot encoding","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/onehot_to_factor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"One hot encoding A supplementarty function for one-hot encoding ‚Äî onehot_to_factor","text":"","code":"onehot_to_factor(onehot_dat)"},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/onehot_to_factor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"One hot encoding A supplementarty function for one-hot encoding ‚Äî onehot_to_factor","text":"onehot_dat data coded factor_to_onehot function.","code":""}]
