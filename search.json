[{"path":"https://krystynagrzesiak.github.io/miceDRF/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Krystyna Grzesiak. Author, contributor. Jeffrey Näf. Author, maintainer.","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Grzesiak K, Näf J (2025). miceDRF: MICE Distributional Random Forest Imputation. R package version 0.1.0, https://github.com/KrystynaGrzesiak/miceDRF.","code":"@Manual{,   title = {miceDRF: MICE and Distributional Random Forest for Imputation},   author = {Krystyna Grzesiak and Jeffrey Näf},   year = {2025},   note = {R package version 0.1.0},   url = {https://github.com/KrystynaGrzesiak/miceDRF}, }"},{"path":"https://krystynagrzesiak.github.io/miceDRF/index.html","id":"micedrf-imputation-with-mice-drf-and-i-score","dir":"","previous_headings":"","what":"MICE and Distributional Random Forest for Imputation","title":"MICE and Distributional Random Forest for Imputation","text":"miceDRF R package extends functionality mice package providing new method handling missing data using Distributed Random Forests (DRF).","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"MICE and Distributional Random Forest for Imputation","text":"install latest development version directly GitHub, run following code R console:","code":"if (!requireNamespace(\"devtools\", quietly = TRUE)) {   install.packages(\"devtools\") } devtools::install_github(\"KrystynaGrzesiak/miceDRF\")"},{"path":"https://krystynagrzesiak.github.io/miceDRF/index.html","id":"example-usage","dir":"","previous_headings":"","what":"Example usage","title":"MICE and Distributional Random Forest for Imputation","text":"","code":"library(miceDRF) library(mice)  # Generate a random dataset n <- 200 d <- 5 X <- matrix(runif(n * d), nrow = n, ncol = d)  # Introduce missing values pmiss <- 0.2 X.NA <- apply(X, 2, function(x) {   U <- runif(length(x))   ifelse(U <= pmiss, NA, x) })  # Perform imputation with DRF method imp <- mice(X.NA, m = 1, method = \"DRF\") Ximp <- complete(imp)"},{"path":"https://krystynagrzesiak.github.io/miceDRF/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"MICE and Distributional Random Forest for Imputation","text":"use miceDRF research, please cite following work: https://doi.org/10.48550/arXiv.2403.19196","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/Iscore.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculates score for one imputation function — Iscore","title":"Calculates score for one imputation function — Iscore","text":"Calculates score one imputation function","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/Iscore.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates score for one imputation function — Iscore","text":"","code":"Iscore(   X,   X_imp,   multiple = TRUE,   N = 50,   imputation_func,   max_length = NULL,   skip_if_needed = TRUE,   scale = FALSE )"},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/Iscore.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculates score for one imputation function — Iscore","text":"X data containing missing values denoted NA's X_imp imputed dataset. multiple logical indicating whether provided imputation method multiple imputation approach (.e. generates different values impute call). Default TRUE. Note multiple equals FALSE, N automatically set 1. N numeric value. Number samples imputation distribution H. Default 50. imputation_func function imputes data max_length Maximum number variables \\(X_j\\) consider, can speed code. Default NULL meaning columns taken consideration. skip_if_needed logical, indicating whether observations skipped obtain complete columns scoring. FALSE, NA returned column observed variable training. scale logica. TRUE, variable scaled score.","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/Iscore.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculates score for one imputation function — Iscore","text":"numerical value denoting weighted Imputation Score obtained provided imputation function table scores weights calculated particular columns.","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/Iscore.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculates score for one imputation function — Iscore","text":"","code":"set.seed(111) X <- matrix(rnorm(1000), nrow = 100) X[runif(1000) < 0.4] <- NA imputation_func <- miceDRF:::create_mice_imputation(\"pmm\") X_imp <- imputation_func(X)  miceDRF::Iscore(X, X_imp, N = 50, imputation_func = imputation_func) #> No complete variables for training column 1. Skipping some observations. #> No complete variables for training column 3. Skipping some observations. #> No complete variables for training column 8. Skipping some observations. #> No complete variables for training column 10. Skipping some observations. #> No complete variables for training column 5. Skipping some observations. #> No complete variables for training column 6. Skipping some observations. #> No complete variables for training column 7. Skipping some observations. #> No complete variables for training column 4. Skipping some observations. #> No complete variables for training column 9. Skipping some observations. #> No complete variables for training column 2. Skipping some observations. #> [1] 0.5583584 #> attr(,\"dat\") #>     column_id weight     score n_columns_used #> V1          1 0.2499 0.5616408              1 #> V3          3 0.2491 0.4377913              1 #> V8          8 0.2475 0.5055475              1 #> V10        10 0.2475 0.5922144              1 #> V5          5 0.2464 0.6850586              1 #> V6          6 0.2436 0.5006411              1 #> V7          7 0.2379 0.6925815              1 #> V4          4 0.2331 0.5294290              1 #> V9          9 0.2331 0.5369845              1 #> V2          2 0.2244 0.5429367              1  imputation_func <- miceDRF:::create_mice_imputation(\"mean\") X_imp <- imputation_func(X)  miceDRF::Iscore(X, X_imp, N = 50, imputation_func = imputation_func) #> No complete variables for training column 1. Skipping some observations. #> No complete variables for training column 3. Skipping some observations. #> No complete variables for training column 8. Skipping some observations. #> No complete variables for training column 10. Skipping some observations. #> No complete variables for training column 5. Skipping some observations. #> No complete variables for training column 6. Skipping some observations. #> No complete variables for training column 7. Skipping some observations. #> No complete variables for training column 4. Skipping some observations. #> No complete variables for training column 9. Skipping some observations. #> No complete variables for training column 2. Skipping some observations. #> [1] 0.7652515 #> attr(,\"dat\") #>     column_id weight     score n_columns_used #> V1          1 0.2499 0.7787504              1 #> V3          3 0.2491 0.6142445              1 #> V8          8 0.2475 0.7015580              1 #> V10        10 0.2475 0.7621273              1 #> V5          5 0.2464 0.9875052              1 #> V6          6 0.2436 0.6425266              1 #> V7          7 0.2379 0.9592499              1 #> V4          4 0.2331 0.7665391              1 #> V9          9 0.2331 0.7250410              1 #> V2          2 0.2244 0.7154879              1  miceDRF::Iscore(X, X_imp, N = 50, imputation_func = imputation_func, multiple = FALSE) #> No complete variables for training column 1. Skipping some observations. #> No complete variables for training column 3. Skipping some observations. #> No complete variables for training column 8. Skipping some observations. #> No complete variables for training column 10. Skipping some observations. #> No complete variables for training column 5. Skipping some observations. #> No complete variables for training column 6. Skipping some observations. #> No complete variables for training column 7. Skipping some observations. #> No complete variables for training column 4. Skipping some observations. #> No complete variables for training column 9. Skipping some observations. #> No complete variables for training column 2. Skipping some observations. #> [1] 0.7652515 #> attr(,\"dat\") #>     column_id weight     score n_columns_used #> V1          1 0.2499 0.7787504              1 #> V3          3 0.2491 0.6142445              1 #> V8          8 0.2475 0.7015580              1 #> V10        10 0.2475 0.7621273              1 #> V5          5 0.2464 0.9875052              1 #> V6          6 0.2436 0.6425266              1 #> V7          7 0.2379 0.9592499              1 #> V4          4 0.2331 0.7665391              1 #> V9          9 0.2331 0.7250410              1 #> V2          2 0.2244 0.7154879              1  # zero imputation X <- matrix(rnorm(1000), nrow = 100) X[c(runif(1000) < 0.3)] <- NA imputation_func <- function(X) {X[is.na(X)] <- 0; X} X_imp <- imputation_func(X)  Iscore(X, X_imp, N = 50, imputation_func = imputation_func, multiple = FALSE) #> No complete variables for training column 5. Skipping some observations. #> No complete variables for training column 7. Skipping some observations. #> No complete variables for training column 2. Skipping some observations. #> No complete variables for training column 4. Skipping some observations. #> No complete variables for training column 8. Skipping some observations. #> No complete variables for training column 6. Skipping some observations. #> No complete variables for training column 1. Skipping some observations. #> No complete variables for training column 10. Skipping some observations. #> No complete variables for training column 3. Skipping some observations. #> No complete variables for training column 9. Skipping some observations. #> [1] 0.8265311 #> attr(,\"dat\") #>     column_id weight     score n_columns_used #> V5          5 0.2400 0.7023632              1 #> V7          7 0.2275 0.8767438              1 #> V2          2 0.2211 0.8043624              1 #> V4          4 0.2100 0.9224779              1 #> V8          8 0.2100 0.8895373              1 #> V6          6 0.2059 0.7644872              1 #> V1          1 0.1971 0.7896345              1 #> V10        10 0.1971 0.8515953              1 #> V3          3 0.1924 0.8454487              1 #> V9          9 0.1659 0.8347622              1"},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/Iscore_cat.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculates score for a single imputation function — Iscore_cat","title":"Calculates score for a single imputation function — Iscore_cat","text":"Calculates score single imputation function","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/Iscore_cat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates score for a single imputation function — Iscore_cat","text":"","code":"Iscore_cat(   X,   X_imp,   imputation_func,   factor_vars = TRUE,   multiple = TRUE,   N = 50,   max_length = NULL,   skip_if_needed = TRUE )"},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/Iscore_cat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculates score for a single imputation function — Iscore_cat","text":"X data containing missing values denoted NA's X_imp imputed dataset. imputation_func function imputes data factor_vars logical value indicating whether imputation performed factors. FALSE, variables factors converted numeric values. multiple logical indicating whether provided imputation method multiple imputation approach (.e. generates different values impute call). Default TRUE. Note multiple equals FALSE, N automatically set 1. N numeric value. Number samples imputation distribution H. Default 50. max_length Maximum number variables \\(X_j\\) consider, can speed code. Default NULL meaning columns taken consideration. skip_if_needed logical, indicating whether observations skipped obtain complete columns scoring. FALSE, NA returned column observed variable training.","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/Iscore_cat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculates score for a single imputation function — Iscore_cat","text":"numerical value denoting weighted Imputation Score obtained provided imputation function table scores weights calculated particular columns.","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/Iscore_cat.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculates score for a single imputation function — Iscore_cat","text":"categorical variables stored factors. need additional conversion data (example one-hot encoding) imputation, please, implement everything within imputation_func parameter. can use miceDRF:::onehot_to_factor miceDRF:::factor_to_onehot functions.","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/Iscore_cat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculates score for a single imputation function — Iscore_cat","text":"","code":"set.seed(123) X <- matrix(rnorm(500), nrow = 100) X <- cbind(X, factor(sample(1:5, 100, replace = TRUE), levels = 1:5)) X[runif(600) < 0.2] <- NA X <- cbind(X, factor(sample(1:2, 100, replace = TRUE), levels = 1:2)) X <- as.data.frame(X) X[[\"V6\"]] <- factor(X[[\"V6\"]], levels = 1:5) X[[\"V7\"]] <- factor(X[[\"V7\"]], levels = 1:2) X[[\"V8\"]] <- rnorm(100) imputation_func <- miceDRF:::create_mice_imputation(\"cart\") X_imp <- imputation_func(X)  Iscore_cat(X, X_imp, imputation_func, factor_vars = FALSE) #> [1] 0.6935389 #> attr(,\"dat\") #>    column_id weight     score n_columns_used #> V1         1 0.1971 0.6819397              2 #> V5         5 0.1924 0.6718325              2 #> V3         3 0.1600 0.7061233              2 #> V6         6 0.1539 0.6258925              2 #> V2         2 0.1476 0.7203252              2 #> V4         4 0.1275 0.7790775              2"},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/Iscores_compare.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculates IScores for multiple imputation functions — Iscores_compare","title":"Calculates IScores for multiple imputation functions — Iscores_compare","text":"Calculates IScores multiple imputation functions","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/Iscores_compare.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates IScores for multiple imputation functions — Iscores_compare","text":"","code":"Iscores_compare(   X,   imputation_list,   methods = NULL,   N = 50,   max_length = NULL,   skip_if_needed = TRUE )"},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/Iscores_compare.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculates IScores for multiple imputation functions — Iscores_compare","text":"imputation_list list imputation functions methods character vector names methods imputation_list. can NULL, function attempt get names imputation_list object.","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/Iscores_compare.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculates IScores for multiple imputation functions — Iscores_compare","text":"vector IScores provided methods","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/Iscores_compare.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculates IScores for multiple imputation functions — Iscores_compare","text":"","code":"set.seed(111) X <- matrix(rnorm(1000), nrow = 100) X[runif(1000) < 0.4] <- NA  methods <- c(\"pmm\", \"cart\", \"sample\", \"norm.nob\", \"DRF\") imputation_list <- create_mice_imputations(methods)  Iscores_compare(X, imputation_list) #> [1] \"Calculating score for method: pmm\" #> No complete variables for training column 1. Skipping some observations. #> No complete variables for training column 3. Skipping some observations. #> No complete variables for training column 8. Skipping some observations. #> No complete variables for training column 10. Skipping some observations. #> No complete variables for training column 5. Skipping some observations. #> No complete variables for training column 6. Skipping some observations. #> No complete variables for training column 7. Skipping some observations. #> No complete variables for training column 4. Skipping some observations. #> No complete variables for training column 9. Skipping some observations. #> No complete variables for training column 2. Skipping some observations. #> [1] \"Calculating score for method: cart\" #> No complete variables for training column 1. Skipping some observations. #> No complete variables for training column 3. Skipping some observations. #> No complete variables for training column 8. Skipping some observations. #> No complete variables for training column 10. Skipping some observations. #> No complete variables for training column 5. Skipping some observations. #> No complete variables for training column 6. Skipping some observations. #> No complete variables for training column 7. Skipping some observations. #> No complete variables for training column 4. Skipping some observations. #> No complete variables for training column 9. Skipping some observations. #> No complete variables for training column 2. Skipping some observations. #> [1] \"Calculating score for method: sample\" #> No complete variables for training column 1. Skipping some observations. #> No complete variables for training column 3. Skipping some observations. #> No complete variables for training column 8. Skipping some observations. #> No complete variables for training column 10. Skipping some observations. #> No complete variables for training column 5. Skipping some observations. #> No complete variables for training column 6. Skipping some observations. #> No complete variables for training column 7. Skipping some observations. #> No complete variables for training column 4. Skipping some observations. #> No complete variables for training column 9. Skipping some observations. #> No complete variables for training column 2. Skipping some observations. #> [1] \"Calculating score for method: norm.nob\" #> No complete variables for training column 1. Skipping some observations. #> No complete variables for training column 3. Skipping some observations. #> No complete variables for training column 8. Skipping some observations. #> No complete variables for training column 10. Skipping some observations. #> No complete variables for training column 5. Skipping some observations. #> No complete variables for training column 6. Skipping some observations. #> No complete variables for training column 7. Skipping some observations. #> No complete variables for training column 4. Skipping some observations. #> No complete variables for training column 9. Skipping some observations. #> No complete variables for training column 2. Skipping some observations. #> [1] \"Calculating score for method: DRF\" #> No complete variables for training column 1. Skipping some observations. #> No complete variables for training column 3. Skipping some observations. #> No complete variables for training column 8. Skipping some observations. #> No complete variables for training column 10. Skipping some observations. #> No complete variables for training column 5. Skipping some observations. #> No complete variables for training column 6. Skipping some observations. #> No complete variables for training column 7. Skipping some observations. #> No complete variables for training column 4. Skipping some observations. #> No complete variables for training column 9. Skipping some observations. #> No complete variables for training column 2. Skipping some observations. #>    sample  norm.nob       pmm       DRF      cart  #> 0.5485229 0.5488967 0.5583584 0.5702948 0.5797292"},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/create_mice_imputation.html","id":null,"dir":"Reference","previous_headings":"","what":"Very internal function for getting mice methods — create_mice_imputation","title":"Very internal function for getting mice methods — create_mice_imputation","text":"internal function getting mice methods","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/create_mice_imputation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Very internal function for getting mice methods — create_mice_imputation","text":"","code":"create_mice_imputation(method)"},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/create_mice_imputation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Very internal function for getting mice methods — create_mice_imputation","text":"","code":"methods <- \"pmm\" imputation_funcs <- create_mice_imputations(methods)"},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/create_mice_imputations.html","id":null,"dir":"Reference","previous_headings":"","what":"A function creating list of mice imputation functions — create_mice_imputations","title":"A function creating list of mice imputation functions — create_mice_imputations","text":"function creating list mice imputation functions","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/create_mice_imputations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A function creating list of mice imputation functions — create_mice_imputations","text":"","code":"create_mice_imputations(methods)"},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/create_mice_imputations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A function creating list of mice imputation functions — create_mice_imputations","text":"methods character vector names mice methods","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/create_mice_imputations.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A function creating list of mice imputation functions — create_mice_imputations","text":"","code":"methods <- c(\"pmm\", \"cart\", \"sample\", \"norm.nob\", \"DRF\") reate_mice_imputations(methods) #> Error in reate_mice_imputations(methods): could not find function \"reate_mice_imputations\""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/do_one_hot.html","id":null,"dir":"Reference","previous_headings":"","what":"One hot encoding A supplementarty function for one-hot encoding — do_one_hot","title":"One hot encoding A supplementarty function for one-hot encoding — do_one_hot","text":"One hot encoding supplementarty function one-hot encoding","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/do_one_hot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"One hot encoding A supplementarty function for one-hot encoding — do_one_hot","text":"","code":"do_one_hot(vec)"},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/do_one_hot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"One hot encoding A supplementarty function for one-hot encoding — do_one_hot","text":"vec factor vector encoded","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/energy_dist.html","id":null,"dir":"Reference","previous_headings":"","what":"Energy distance — energy_dist","title":"Energy distance — energy_dist","text":"function wrapper energy distance calculating. details see eqdist.e.","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/energy_dist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Energy distance — energy_dist","text":"","code":"energy_dist(X, X_imp)"},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/energy_dist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Energy distance — energy_dist","text":"X complete original dataset X_imp imputed dataset","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/energy_dist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Energy distance — energy_dist","text":"","code":"X <- matrix(rnorm(1000), nrow = 100) X_imp <- matrix(rnorm(1000), nrow = 100) energy_dist(X, X_imp) #> E-statistic  #>    2.856983"},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/factor_to_numeric.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal function for changing factors to numerical A supplementarty function for data management — factor_to_numeric","title":"Internal function for changing factors to numerical A supplementarty function for data management — factor_to_numeric","text":"Internal function changing factors numerical supplementarty function data management","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/factor_to_numeric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal function for changing factors to numerical A supplementarty function for data management — factor_to_numeric","text":"","code":"factor_to_numeric(factor_col)"},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/factor_to_numeric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal function for changing factors to numerical A supplementarty function for data management — factor_to_numeric","text":"factor_col factor column","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/factor_to_onehot.html","id":null,"dir":"Reference","previous_headings":"","what":"One hot encoding A supplementarty function for one-hot encoding — factor_to_onehot","title":"One hot encoding A supplementarty function for one-hot encoding — factor_to_onehot","text":"One hot encoding supplementarty function one-hot encoding","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/factor_to_onehot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"One hot encoding A supplementarty function for one-hot encoding — factor_to_onehot","text":"","code":"factor_to_onehot(dat)"},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/factor_to_onehot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"One hot encoding A supplementarty function for one-hot encoding — factor_to_onehot","text":"dat data containinig factor numeric columns.","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/hello.html","id":null,"dir":"Reference","previous_headings":"","what":"Hello, World! — hello","title":"Hello, World! — hello","text":"Prints 'Hello, world!'.","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/hello.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hello, World! — hello","text":"","code":"hello()"},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/hello.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hello, World! — hello","text":"","code":"hello() #> Error in hello(): could not find function \"hello\""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/impute_mice_drf.html","id":null,"dir":"Reference","previous_headings":"","what":"mice DRF (Distributional Random Forest) — impute_mice_drf","title":"mice DRF (Distributional Random Forest) — impute_mice_drf","text":"function performs imputation using MICE Distributional Random Forest","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/impute_mice_drf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"mice DRF (Distributional Random Forest) — impute_mice_drf","text":"","code":"impute_mice_drf(missdf, printFlag = FALSE, m = 1, ...)"},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/impute_mice_drf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"mice DRF (Distributional Random Forest) — impute_mice_drf","text":"missdf incomplete dataset missing values denoted NA's printFlag logical, indicating whether silent computations performed. Default FALSE. m number imputed datasets generate ... used compatibility mice package.","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/impute_mice_drf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"mice DRF (Distributional Random Forest) — impute_mice_drf","text":"completed dataset","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/impute_mice_drf.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"mice DRF (Distributional Random Forest) — impute_mice_drf","text":"method described detail : Näf, J., Scornet, E., & Josse, J. (2024). good imputation MAR missingness?. arXiv. https://arxiv.org/abs/2403.19196 based : Cevid, D., Michel, L., Näf, J., Meinshausen, N., B¨ uhlmann, P. (2022). Distributional random forests: Heterogeneity adjustment multivariate distributional regression. Journal Machine Learning Research, 23(333):1–79.","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/impute_mice_drf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"mice DRF (Distributional Random Forest) — impute_mice_drf","text":"","code":"X <- matrix(rnorm(1000), nrow = 100) X[c(runif(700), rep(1, 300)) < 0.3] <- NA impute_mice_drf(X, printFlag = TRUE) #>  #>  iter imp variable #>   1   1  V1  V2  V3  V4  V5  V6  V7 #>   2   1  V1  V2  V3  V4  V5  V6  V7 #>   3   1  V1  V2  V3  V4  V5  V6  V7 #>   4   1  V1  V2  V3  V4  V5  V6  V7 #>   5   1  V1  V2  V3  V4  V5  V6  V7 #>               V1           V2           V3           V4           V5 #> 1    1.286881639 -1.146127540 -1.287311583 -0.105540370  0.486490770 #> 2    0.336726244  0.856525578 -0.055972957  1.389084827  0.561637619 #> 3    0.719406326 -0.086366504 -0.721402793  2.175713757 -1.430085891 #> 4    0.619254552 -1.106474590  0.683950483 -0.195912140 -0.066536251 #> 5    0.059178320 -0.079987909  0.087854435 -1.347760319  0.003043269 #> 6   -0.791940856  0.613083606  2.054933912  0.346777762  0.539804286 #> 7    0.817477625 -0.153170023 -1.209440108 -0.125799319  1.826597003 #> 8    0.817477625 -0.293199334  0.683950483 -0.091087050  2.071142956 #> 9   -0.471985957 -1.109778336 -0.170695971 -0.623413671  1.826597003 #> 10   0.838185816 -0.502129000  0.290448039 -0.195912140  1.426383031 #> 11  -0.575894613  0.805096892 -0.528577183  0.038769577  1.535334184 #> 12   0.673921583  0.029503727 -1.313754437  1.578861290 -0.724563506 #> 13  -1.640928322 -0.156188761 -1.152557256  2.175713757  2.621439633 #> 14   0.846497232 -0.042339989 -0.556984384  2.047283560  0.832068087 #> 15   0.673921583 -0.319740990 -0.849637404 -0.992391446 -0.389395393 #> 16  -0.080967979  1.102187440 -0.763310495 -0.597744804  0.314597297 #> 17   1.623927907 -1.731975849 -0.798780780  0.618099405 -0.049874742 #> 18  -1.640928322 -0.156188761  0.748758383  0.503180263 -1.844161498 #> 19   1.504131226 -0.079987909 -0.317028901 -1.989486533  1.535334184 #> 20   0.329896158  0.613083606 -0.434049882  1.389084827 -0.939318211 #> 21  -0.480376893  0.632021417  0.279139631 -1.317971453  1.180592313 #> 22  -1.494296737  0.242247923 -0.889790415  0.416927807 -1.208281338 #> 23  -0.703484581  0.029503727  0.772231287  0.131555661 -0.657355312 #> 24  -0.294908722  0.856525578 -0.239392802  0.131555661  1.826597003 #> 25  -0.169382258  0.500415016 -1.209440108 -0.655364956  0.544346904 #> 26   0.410811111 -0.997468040  0.821819472 -0.623413671 -1.430085891 #> 27   0.185390566 -1.371366652  1.863591936 -0.539536393  0.328974216 #> 28  -0.296380992  1.431845075 -1.000836479  1.682888846  1.027789907 #> 29  -0.678785596 -0.229365189 -0.434049882  0.312710958 -0.173587690 #> 30   0.153783466  0.304539693 -1.171796995 -0.582225157 -0.724563506 #> 31   0.081796735 -0.475148778  0.240248965 -1.235442014 -0.853365317 #> 32   0.673921583 -0.462163972 -1.251852207  1.360752822  1.278136973 #> 33   0.318432826  0.856525578 -0.239392802 -0.127961506 -0.712990916 #> 34  -0.329218091 -0.836379050  0.657013022 -0.655364956  0.696815400 #> 35   0.336726244 -1.977855558 -1.000836479 -0.650394043 -1.766545941 #> 36   0.009271358  0.001271804  1.193206862  0.540530065 -1.087288977 #> 37   1.875960495 -0.203272992  0.740464445 -0.763510323 -0.939318211 #> 38   1.875960495 -0.684584618  0.289227688  0.178345752 -0.073981645 #> 39  -0.575894613 -1.731975849 -0.484251474 -0.596517974 -0.389395393 #> 40   0.122370796 -0.513044459  0.821819472 -0.623413671  0.719673323 #> 41  -0.138458667  0.242247923 -0.317028901 -0.223518335  1.756613966 #> 42   1.684380297  0.856525578 -1.171796995 -0.250163336  0.632786540 #> 43  -0.662692344 -0.908734798 -0.057414156 -0.582225157 -0.556727565 #> 44   0.883228555  0.587217018 -0.798780780 -0.007620419  1.080828209 #> 45   0.817477625 -0.032502035  0.181522563 -0.655364956  0.142185519 #> 46  -0.080967979 -0.765246153  0.367137188 -1.380014509  1.041690149 #> 47  -0.341234792  0.203872954  0.903329722 -1.153520612 -0.718046731 #> 48   0.838185816 -0.363584441 -0.008721016 -1.116790589 -1.208281338 #> 49   1.579845621 -1.424211154  0.625236835  0.539548679 -0.893915325 #> 50  -0.332983960 -0.965746254 -0.311908313  0.382250687  0.923698265 #> 51  -1.494296737  1.740567496 -0.889790415  0.368126128  0.440262312 #> 52  -0.616328175  0.587217018  1.004668630  1.961815724  0.842274667 #> 53   1.464016231 -0.828102358  1.583152058  0.540530065 -1.087288977 #> 54   0.592616090  0.632021417 -0.317028901 -1.317971453  1.752240265 #> 55   0.326365318 -1.915176469 -0.239392802  0.463900554 -0.006167482 #> 56  -0.180470334  0.856525578 -1.251852207  0.207911097 -0.173610187 #> 57  -0.575894613  0.219698084 -0.239392802 -0.358770506 -0.173610187 #> 58  -0.660647254  1.775738591 -0.232106812  0.440929825 -0.488356802 #> 59  -0.167649066  0.029503727  1.193206862 -0.223518335  0.511616545 #> 60  -0.660647254  0.841352749  1.005830746  0.207911097 -1.844161498 #> 61  -0.662692344 -0.769807637 -0.055972957  2.226737811 -0.377536227 #> 62   0.063634707  1.361406606  0.821819472  0.696590320  0.588013747 #> 63  -1.504531739 -0.079987909 -0.526421017  2.175713757  0.054892200 #> 64   0.480151337 -0.531018768 -0.016285264 -0.938561091 -1.233205874 #> 65  -0.713787249  0.816012249  1.263480871  1.578861290  0.062812424 #> 66   0.161921975  1.126586563 -0.026260625 -1.317971453 -1.766545941 #> 67  -0.013007870 -0.461012089  0.683950483 -0.582225157  1.278136973 #> 68   0.410811111  0.826341246 -0.072260793 -0.068025517 -0.688044005 #> 69   0.947071303  1.431845075  1.005198805 -0.655364956 -0.264603566 #> 70  -0.560802742 -1.731975849 -0.721250277 -0.650394043  1.125422777 #> 71  -0.083841085 -0.684584618  0.809810155  0.178345752 -1.087288977 #> 72  -0.734731068 -0.836379050 -0.055972957  0.178345752  0.219975811 #> 73   0.541953515  0.073525997 -1.932375589  0.533558855 -0.338561004 #> 74  -0.434635837  0.868971862 -1.237613524 -0.250163336 -0.839033295 #> 75   0.541953515 -0.836379050 -0.016285264  0.595701108  2.297226745 #> 76  -0.261493597 -1.408393108  0.871384168  0.517215347 -0.173587690 #> 77   0.193854282 -0.445191426  0.891146892 -0.623413671 -1.430085891 #> 78  -1.440863380 -0.752133229 -1.000836479 -1.347760319 -2.843903969 #> 79  -1.059238834  1.775738591 -0.721250277 -1.234178814  0.384470742 #> 80   0.334524323  1.989903899  1.136407784  1.067417315  0.810723067 #> 81  -1.428802224  0.548243591 -1.000836479  0.440929825 -1.218317236 #> 82  -0.167649066  0.026341096  1.193984263  1.072055915 -0.414183224 #> 83  -1.267284660  2.093788956  1.143615173  2.663982198  0.610201872 #> 84   1.379742654  1.460823258 -0.798780780  0.696590320  0.148788755 #> 85  -1.640928322  0.613670714 -0.968625424  2.047283560  0.832068087 #> 86   0.838185816  0.431235347 -0.798780780 -0.091087050  2.071142956 #> 87   0.112709917 -0.908734798 -0.453234242 -0.127961506 -0.246004779 #> 88  -0.662692344  0.281453856 -0.519467400  1.072055915 -0.511453632 #> 89  -0.167649066  1.775738591  0.644238937 -0.143329553  1.426383031 #> 90   0.059178320  0.332603345  0.181522563  2.175713757 -0.389395393 #> 91  -0.662105527  0.360298601  1.143615173 -0.143329553 -0.414183224 #> 92   0.113377108 -1.033702590 -1.114865129  1.389084827  0.539804286 #> 93   1.286881639  0.288981847 -0.889790415 -1.579949560  0.539804286 #> 94  -0.288259952 -0.965746254  0.287424477 -0.763510323  2.297226745 #> 95   0.492039964  0.684289690  0.374446341 -0.582225157  0.588283603 #> 96  -0.994823662 -0.374912346  0.772231287  2.047283560 -1.485946957 #> 97   0.846497232  1.102187440  1.193206862  0.207911097  1.480345125 #> 98   0.838185816  1.350913153 -1.209440108  0.273314464  0.337505528 #> 99   0.900015272 -0.153170023 -0.460968968  0.347778679 -0.712990916 #> 100  0.149229512  2.530880883  0.192143507  0.395176361 -1.087288977 #>               V6          V7          V8           V9          V10 #> 1   -0.506334386 -0.94038863  0.30954407 -0.660340352  0.563727132 #> 2   -0.487547486 -2.04733098 -0.79547942  1.404557699  1.722887443 #> 3    0.627354263 -1.06213683  1.93111704 -1.087238691 -0.446319043 #> 4   -0.122004019 -0.40484620  0.56053724  0.495159038  0.464209238 #> 5    1.181804508 -0.86103932 -1.74630153  0.035439877  0.683688618 #> 6   -0.334988147 -1.47749668 -0.56402757 -0.772153598  0.303492997 #> 7    0.096973976 -0.20471146  0.91004076  0.358623199  0.146856901 #> 8   -0.506334386  2.40900905  1.46205510 -0.070991884 -0.169666635 #> 9    0.883914314 -1.04436575 -0.04213147 -1.870125598  0.454430816 #> 10  -0.051245357  0.19889976  0.01176334  0.330915403 -0.196930126 #> 11  -0.984234083  1.19998051 -0.17612720  0.000520376  0.148387906 #> 12  -1.218266313  0.89196745 -1.16665165 -1.223059834  0.094618250 #> 13   0.788521753 -0.40402752 -0.70085795 -0.950131027 -0.459623227 #> 14  -0.701459961 -0.65878434  1.01817614 -0.543937987 -1.332928624 #> 15  -0.327861857  1.01310694  0.76492355 -0.818050574 -0.272514422 #> 16  -0.330367482 -0.30507282 -1.33026427 -0.568923788  0.275951805 #> 17  -1.166747818  0.47624806  1.38094563  0.905392199  0.600672707 #> 18  -0.470968884 -0.11338919 -0.57383538 -0.079936781 -2.014221834 #> 19  -0.327861857  0.89196745 -0.26382308 -0.395955917  1.584627484 #> 20   1.683935216  1.17413861  0.49313921 -0.497565309  0.840870445 #> 21   0.860888932  0.03338432 -0.66141816  0.104889868  0.882871454 #> 22  -0.209798099  0.08605225 -1.22201315 -1.280133368  0.763517484 #> 23   1.568387123  2.19306193 -0.68049208 -0.779743945  0.874873060 #> 24  -1.362817183 -1.78804246  0.37937841 -1.877766196  0.260855937 #> 25   0.453590809 -0.34571015 -0.22556627  0.929537894  1.223767364 #> 26  -1.083275584 -0.30607712 -1.09041207 -1.640011935  1.160492569 #> 27   0.255739498  0.76684448 -0.04325630 -0.694588214 -0.166991823 #> 28  -0.597305092 -1.37420121 -0.44388440  0.346611582 -1.498935503 #> 29   1.224854057 -0.30571240  0.28656121 -0.316884063 -0.362028451 #> 30  -0.227307438 -0.40484620 -1.54211230  0.474813814 -1.004400808 #> 31   1.148132420  0.11606193 -0.38520177  1.353343832  1.059126452 #> 32  -0.078704194 -0.96860936 -0.66392604  2.282476280 -0.017100474 #> 33  -0.227307438 -0.40484620 -1.33308583  1.176133456  0.578062231 #> 34  -0.122004019 -0.23947810 -0.97117698 -0.463990133 -1.334739539 #> 35   1.032795057  1.09002474 -0.91219310  1.475873010  0.800148659 #> 36  -0.227307438 -0.69060800 -0.06643996 -1.103792987 -0.999821364 #> 37  -1.414387055 -0.89956319 -0.42202678 -2.387478223 -1.232616814 #> 38   0.304557069  0.13889380  2.24627009 -1.392164235 -0.668775151 #> 39  -1.220249639  0.83988117  0.75113000 -0.049269509  0.164242234 #> 40   0.788521753 -0.91471058  0.51734417 -0.901170605 -0.170597752 #> 41   0.310089485  0.03338432 -0.63640359  1.345262778  0.115563319 #> 42  -0.439396920 -0.94038863 -0.56176320  0.111869791 -0.745606869 #> 43  -1.414387055 -0.20793004  1.01687864 -1.534485001 -1.415590033 #> 44   0.991551586  0.59408920  0.17641685  0.870150893 -0.379915961 #> 45  -0.126156858  1.18442064  0.84149019  1.218354938 -0.165558359 #> 46  -0.225451218 -0.30507282 -1.42105069 -0.584779870  0.637425749 #> 47   1.577553937  0.41207011 -0.51094604  0.692002648 -0.468060769 #> 48  -1.115904656 -0.89119837  2.41114714  0.827685653  0.061739673 #> 49  -1.414387055 -0.30571240  0.59417122  1.856614116 -0.341749845 #> 50  -0.597305092 -1.74479100 -0.77035888 -0.321293505  2.129766807 #> 51  -0.643478427  0.50345743 -1.31785488 -1.371266991  0.750312477 #> 52  -0.242346951 -0.64999748 -1.12439288  1.654672389  2.045294957 #> 53  -0.122004019  0.32597526  0.08040567 -0.668042403 -0.713988946 #> 54   1.300319602  0.63794559  0.51718140 -0.575315441  0.009999535 #> 55  -1.166747818 -0.86103932 -0.87059622 -0.415124833 -2.218131324 #> 56   1.953613520  1.97529191  2.57058248  1.435314204  0.570258001 #> 57   0.353627597 -1.06213683 -0.46344343 -2.797881897 -0.198938776 #> 58  -1.115904656 -0.65878434  2.02476307 -0.126725112 -0.458510619 #> 59   1.568387123  2.53432069 -0.97344825 -0.913518615 -0.031454180 #> 60   1.577553937  0.89196745 -1.03490760 -1.151527020  0.140154756 #> 61  -1.311422874 -1.44200492  1.40533448 -0.170082602 -1.507572162 #> 62  -1.166747818 -0.40402752  0.51540196 -1.025576521  1.699335576 #> 63  -0.251592374  0.50345743  0.91935697 -1.180125254  0.646511570 #> 64  -0.968150285 -1.85757154 -1.00327729  0.850880560 -1.932508910 #> 65  -1.240127089  0.13114613  1.73939743 -0.880418845  0.270316192 #> 66   1.211711761  1.13639532 -0.56043291  0.137347957  0.440567693 #> 67   0.160265139  1.27963302 -0.38922835  0.996626751 -0.728270656 #> 68  -0.993431613  0.23405077  1.09218635 -1.267459021  0.162328177 #> 69   1.148132420  0.16754793  0.32346208  0.630351455 -0.647826703 #> 70  -0.808852822  0.23816952  0.04092342 -0.611529129  0.370486324 #> 71   1.378231087  1.17413861 -0.32729339 -1.497865064 -0.492308415 #> 72  -0.506334386 -0.85327177  1.45042234  0.495485524 -0.410927094 #> 73  -0.288325849  0.13889380  0.29076547  1.554843104 -0.601084132 #> 74   0.007330823 -0.19563060  1.08086473  1.173189656 -0.134675523 #> 75  -0.051245357  1.40237230  1.17676933  0.705603666 -0.390111389 #> 76  -0.276155902 -1.52864479 -2.38829461  0.037776992 -0.370976748 #> 77  -0.010196613  0.04793931 -0.53824143 -1.334058852  1.575259511 #> 78  -0.078704194  0.32597526 -0.98837904  0.038252262 -0.436669104 #> 79  -1.722270961  0.89196745 -1.30696308 -0.967607652  1.827817903 #> 80   1.055670041 -0.11338919 -1.10221985 -0.384389521 -0.685294239 #> 81   0.453590809 -1.06213683  0.23234698  0.182817934 -0.773022043 #> 82   1.378231087 -1.06213683 -0.44724503  1.585191098  0.420134208 #> 83   1.419980551 -0.64999748 -1.39506650 -0.536568292  1.171604762 #> 84  -0.541106012  0.44091758 -0.46326196  0.096855966 -1.087096180 #> 85   0.412825400  0.72651143 -0.24928436  0.216811244 -1.615103757 #> 86   0.127049822  0.40452524  1.86067942  0.078917970 -0.198967716 #> 87  -1.460289695 -0.27695751 -0.76574729  0.220997015 -2.080669907 #> 88  -0.808852822 -0.86790942  0.53452681 -0.173640350 -0.447074699 #> 89   1.211711761  0.35460765 -0.06728061  1.375723150  0.241725490 #> 90  -0.126156858 -1.49531853  0.93887656  0.822393098  0.387176191 #> 91  -1.311422874  0.83989485 -0.52969623 -0.207818582  0.153468424 #> 92   0.199681011  0.04793931  0.89960753  0.605831206  0.588469182 #> 93  -0.506334386 -0.94038863 -0.08077534 -1.165042289  0.296213085 #> 94  -1.141391729 -0.26183760  1.06494146  0.093231009 -0.044539142 #> 95   1.300319602  1.34025411 -0.02863485 -1.506688813 -1.388181846 #> 96  -0.202656030 -0.65878434 -1.47751220  0.411238970  0.696735836 #> 97   0.304557069  0.99285364  1.73050262 -1.061507161  0.941216768 #> 98  -1.079315188  0.13114613  0.72451310 -0.014949790 -0.907448029 #> 99  -0.227307438 -0.43597085 -1.04909401  0.661419697 -1.795962050 #> 100 -0.202823642 -0.77001802  0.24868846  0.573087733  1.087486908"},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/mice.impute.DRF.html","id":null,"dir":"Reference","previous_headings":"","what":"mice DRF (Distributional Random Forest) — mice.impute.DRF","title":"mice DRF (Distributional Random Forest) — mice.impute.DRF","text":"function performs imputation using MICE Distributional Random Forest","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/mice.impute.DRF.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"mice DRF (Distributional Random Forest) — mice.impute.DRF","text":"","code":"mice.impute.DRF(   y,   ry,   x,   wy = NULL,   min.node.size = 1,   num.features = 10,   num.trees = 10,   ... )"},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/mice.impute.DRF.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"mice DRF (Distributional Random Forest) — mice.impute.DRF","text":"y words, words... ry words, words... x words, words... wy words, words... min.node.size words, words... num.features words, words... num.trees words, words...","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/mice.impute.DRF.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"mice DRF (Distributional Random Forest) — mice.impute.DRF","text":"method described detail : Näf, J., Scornet, E., & Josse, J. (2024). good imputation MAR missingness?. arXiv. https://arxiv.org/abs/2403.19196 based : Cevid, D., Michel, L., Näf, J., Meinshausen, N., B¨ uhlmann, P. (2022). Distributional random forests: Heterogeneity adjustment multivariate distributional regression. Journal Machine Learning Research, 23(333):1–79.","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/onehot_to_factor.html","id":null,"dir":"Reference","previous_headings":"","what":"One hot encoding A supplementarty function for one-hot encoding — onehot_to_factor","title":"One hot encoding A supplementarty function for one-hot encoding — onehot_to_factor","text":"One hot encoding supplementarty function one-hot encoding","code":""},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/onehot_to_factor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"One hot encoding A supplementarty function for one-hot encoding — onehot_to_factor","text":"","code":"onehot_to_factor(onehot_dat)"},{"path":"https://krystynagrzesiak.github.io/miceDRF/reference/onehot_to_factor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"One hot encoding A supplementarty function for one-hot encoding — onehot_to_factor","text":"onehot_dat data coded factor_to_onehot function.","code":""}]
