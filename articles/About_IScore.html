<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Energy-I-Score: Implementation Details ‚Ä¢ miceDRF</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Energy-I-Score: Implementation Details">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">miceDRF</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/About_IScore.html">Energy-I-Score: Implementation Details</a></li>
    <li><a class="dropdown-item" href="../articles/Example_IScore.html">Energy-I-Score: First Steps</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/KrystynaGrzesiak/miceDRF/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Energy-I-Score: Implementation Details</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/KrystynaGrzesiak/miceDRF/blob/master/vignettes/About_IScore.Rmd" class="external-link"><code>vignettes/About_IScore.Rmd</code></a></small>
      <div class="d-none name"><code>About_IScore.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>This vignette presents the implementation details of the
<em>energy-I-Score</em>, a metric designed to <strong>evaluate the
quality of imputation methods</strong> in incomplete datasets.</p>
<p>The score is based on the concept of <strong>energy distance</strong>
between observed and imputed distributions. It allows comparing the
uncertainty induced by the imputation model with the variability present
in the observed data. The procedure is model-agnostic: it can be used
with any imputation method
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>‚Ñê</mi><annotation encoding="application/x-tex">\mathcal{I}</annotation></semantics></math>
and with multiple imputation draws.</p>
<p>The score is <strong>distribution-free</strong> and can be applied
to:</p>
<ul>
<li>continuous variables,</li>
<li>mixed-type data (here the score is calculated on dummy
variables),</li>
<li>multiple imputation methods.</li>
</ul>
<hr>
<div class="section level3">
<h3 id="notation">Notation<a class="anchor" aria-label="anchor" href="#notation"></a>
</h3>
<p>Let
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>‚àà</mo><msup><mi>‚Ñù</mi><mrow><mi>n</mi><mo>√ó</mo><mi>p</mi></mrow></msup></mrow><annotation encoding="application/x-tex">X \in \mathbb{R}^{n \times p}</annotation></semantics></math>
be an original dataset with missing values,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>X</mi><mo accent="true">ÃÉ</mo></mover><mo>‚àà</mo><msup><mi>‚Ñù</mi><mrow><mi>n</mi><mo>√ó</mo><mi>p</mi></mrow></msup></mrow><annotation encoding="application/x-tex">\tilde{X} \in \mathbb{R}^{n \times p}</annotation></semantics></math>
be an imputed dataset,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>‚Ñê</mi><annotation encoding="application/x-tex">\mathcal{I}</annotation></semantics></math>
imputation function, and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math>
the number of imputations drawn from
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>‚Ñê</mi><annotation encoding="application/x-tex">\mathcal{I}</annotation></semantics></math>.</p>
<p>Then, for each variable with missing values
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi><mo>‚àà</mo><mo stretchy="false" form="prefix">{</mo><mn>1</mn><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><mi>p</mi><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">j \in \{1, \ldots, p\}</annotation></semantics></math>
we define
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>L</mi><mi>j</mi></msub><annotation encoding="application/x-tex">L_j</annotation></semantics></math>
as a set of indices
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>
for which
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>X</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><annotation encoding="application/x-tex">X_{i,j}</annotation></semantics></math>
is observed,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msubsup><mi>L</mi><mi>j</mi><mi>c</mi></msubsup><annotation encoding="application/x-tex">L_j^c</annotation></semantics></math>
being a set of indices
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>
for which
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>X</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><annotation encoding="application/x-tex">X_{i,j}</annotation></semantics></math>
is missing and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>O</mi><mi>j</mi></msub><annotation encoding="application/x-tex">O_j</annotation></semantics></math>
a set of fully observed predictor variables for rows with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>X</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><annotation encoding="application/x-tex">X_{i,j}</annotation></semantics></math>
observed.</p>
<p>Finally, we define the set of variables with missing values as
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ùíÆ</mi><mo>=</mo><mo stretchy="false" form="prefix">{</mo><mi>j</mi><mo>:</mo><msubsup><mi>L</mi><mi>j</mi><mi>c</mi></msubsup><mo>‚â†</mo><mi>‚àÖ</mi><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">\mathcal{S} = \{ j : L_j^c \neq \emptyset \}</annotation></semantics></math>.</p>
<hr>
</div>
<div class="section level3">
<h3 id="algorithm-overview">Algorithm Overview<a class="anchor" aria-label="anchor" href="#algorithm-overview"></a>
</h3>
<p>The <em>energy-I-Score</em> is computed iteratively for each variable
with missing data. The following steps are performed for each
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi><mo>‚àà</mo><mi>ùíÆ</mi></mrow><annotation encoding="application/x-tex">j \in \mathcal{S}</annotation></semantics></math>.</p>
<div class="section level4">
<h4 id="step-1-selection-of-predictor-set">Step 1: Selection of Predictor Set<a class="anchor" aria-label="anchor" href="#step-1-selection-of-predictor-set"></a>
</h4>
<p>We determine the set of predictor variables:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>O</mi><mi>j</mi></msub><mo>=</mo><munder><mo>‚ãÇ</mo><mrow><mi>m</mi><mo>‚àà</mo><msub><mi>L</mi><mi>j</mi></msub></mrow></munder><mo stretchy="false" form="prefix">{</mo><mi>l</mi><mo>:</mo><msub><mi>m</mi><mi>l</mi></msub><mo>=</mo><mn>0</mn><mo stretchy="false" form="postfix">}</mo><mi>.</mi></mrow><annotation encoding="application/x-tex">
O_j = \bigcap_{m \in L_j} \{ l : m_l = 0 \}.
</annotation></semantics></math></p>
<p>If
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>O</mi><mi>j</mi></msub><annotation encoding="application/x-tex">O_j</annotation></semantics></math>
is empty, the algorithm automatically selects a fallback variable
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>k</mi><mo>*</mo></msup><annotation encoding="application/x-tex">k^*</annotation></semantics></math>
defined as:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>k</mi><mo>*</mo></msup><mo>=</mo><msub><mtext mathvariant="normal">argmax</mtext><mrow><mi>k</mi><mo>‚â†</mo><mi>j</mi></mrow></msub><mo minsize="1.2" maxsize="1.2" stretchy="false" form="prefix">|</mo><mo stretchy="false" form="prefix">{</mo><mi>i</mi><mo>:</mo><msub><mi>m</mi><mrow><mi>i</mi><mo>,</mo><mo>‚ãÖ</mo></mrow></msub><mo>‚àà</mo><msub><mi>L</mi><mi>j</mi></msub><mo>‚à©</mo><msub><mi>L</mi><mi>k</mi></msub><mo stretchy="false" form="postfix">}</mo><mo minsize="1.2" maxsize="1.2" stretchy="false" form="prefix">|</mo><mi>.</mi></mrow><annotation encoding="application/x-tex">
k^* = \text{argmax}_{k \neq j} \big|\{ i : m_{i,\cdot} \in L_j \cap L_k \}\big|.
</annotation></semantics></math> which is a variable with the largest
number of observed values for the observed part of column
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>.
This ensures that the imputation model has at least one predictor.</p>
</div>
<div class="section level4">
<h4 id="step-2-data-partitioning">Step 2: Data Partitioning<a class="anchor" aria-label="anchor" href="#step-2-data-partitioning"></a>
</h4>
<p>The data are split into training and test sets as follows:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext mathvariant="normal">Train</mtext><mo>=</mo><mrow><mo stretchy="true" form="prefix">[</mo><mtable><mtr><mtd columnalign="center" style="text-align: center"><mrow><mi mathvariant="normal">N</mi><mi mathvariant="normal">A</mi></mrow></mtd><mtd columnalign="center" style="text-align: center"><msub><mover><mi>X</mi><mo accent="true">ÃÉ</mo></mover><mrow><msub><mi>L</mi><mi>j</mi></msub><mo>,</mo><msub><mi>O</mi><mi>j</mi></msub></mrow></msub></mtd></mtr><mtr><mtd columnalign="center" style="text-align: center"><msub><mover><mi>X</mi><mo accent="true">ÃÉ</mo></mover><mrow><msubsup><mi>L</mi><mi>j</mi><mi>c</mi></msubsup><mo>,</mo><mi>j</mi></mrow></msub></mtd><mtd columnalign="center" style="text-align: center"><msub><mover><mi>X</mi><mo accent="true">ÃÉ</mo></mover><mrow><msubsup><mi>L</mi><mi>j</mi><mi>c</mi></msubsup><mo>,</mo><msub><mi>O</mi><mi>j</mi></msub></mrow></msub></mtd></mtr></mtable><mo stretchy="true" form="postfix">]</mo></mrow><mo>,</mo><mspace width="1.0em"></mspace><mtext mathvariant="normal">Test</mtext><mo>=</mo><mrow><mo stretchy="true" form="prefix">[</mo><mtable><mtr><mtd columnalign="center" style="text-align: center"><msub><mover><mi>X</mi><mo accent="true">ÃÉ</mo></mover><mrow><msub><mi>L</mi><mi>j</mi></msub><mo>,</mo><mi>j</mi></mrow></msub></mtd></mtr></mtable><mo stretchy="true" form="postfix">]</mo></mrow><mi>.</mi></mrow><annotation encoding="application/x-tex">
\text{Train} =
\begin{bmatrix}
\mathrm{NA} &amp; \tilde{X}_{L_j, O_j} \\
\tilde{X}_{L_j^c, j} &amp; \tilde{X}_{L_j^c, O_j}
\end{bmatrix},
\quad
\text{Test} =
\begin{bmatrix}
\tilde{X}_{L_j, j}
\end{bmatrix}.
</annotation></semantics></math></p>
<ul>
<li>The <strong>training set</strong> contains the observed predictor
values and missing target values to be imputed.</li>
<li>The <strong>test set</strong> contains the observed target values to
evaluate imputation quality.</li>
</ul>
</div>
<div class="section level4">
<h4 id="step-3-multiple-imputations">Step 3: Multiple Imputations<a class="anchor" aria-label="anchor" href="#step-3-multiple-imputations"></a>
</h4>
<p>The missing part of the training set is imputed
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math>
times using
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>‚Ñê</mi><annotation encoding="application/x-tex">\mathcal{I}</annotation></semantics></math>:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mover><mi>X</mi><mo accent="true">ÃÉ</mo></mover><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><msubsup><mover><mi>X</mi><mo accent="true">ÃÉ</mo></mover><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mi>N</mi><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo>‚àº</mo><msub><mi>H</mi><mrow><msub><mi>X</mi><mi>j</mi></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>X</mi><msub><mi>O</mi><mi>j</mi></msub></msub><mo>,</mo><msub><mi>M</mi><mi>j</mi></msub><mo>=</mo><mn>1</mn></mrow></msub><mi>.</mi></mrow><annotation encoding="application/x-tex">
\tilde{X}_{i,j}^{(1)}, \ldots, \tilde{X}_{i,j}^{(N)} \sim H_{X_j|X_{O_j}, M_j = 1}.
</annotation></semantics></math></p>
<p>Each imputation represents a draw from the conditional distribution
of the missing variable given the observed predictors.</p>
</div>
<div class="section level4">
<h4 id="step-4-energy-distance-calculation">Step 4: Energy Distance Calculation<a class="anchor" aria-label="anchor" href="#step-4-energy-distance-calculation"></a>
</h4>
<p>For each
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo>‚àà</mo><msub><mi>L</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">i \in L_j</annotation></semantics></math>,
the <em>energy-I-Score</em> component is computed as:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mover><mi>S</mi><mo accent="true">ÃÇ</mo></mover><mrow><mi mathvariant="normal">N</mi><mi mathvariant="normal">A</mi></mrow><mi>j</mi></msubsup><mrow><mo stretchy="true" form="prefix">(</mo><mi>H</mi><mo>,</mo><mi>P</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mfrac><mn>1</mn><mrow><mo stretchy="true" form="prefix">|</mo><msub><mi>L</mi><mi>j</mi></msub><mo stretchy="true" form="postfix">|</mo></mrow></mfrac><munder><mo>‚àë</mo><mrow><mi>i</mi><mo>‚àà</mo><msub><mi>L</mi><mi>j</mi></msub></mrow></munder><mrow><mo stretchy="true" form="prefix">[</mo><mfrac><mn>1</mn><mrow><mn>2</mn><msup><mi>N</mi><mn>2</mn></msup></mrow></mfrac><munderover><mo>‚àë</mo><mrow><mi>l</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><munderover><mo>‚àë</mo><mrow><mo>‚Ñì</mo><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mrow><mo stretchy="true" form="prefix">|</mo><msubsup><mover><mi>X</mi><mo accent="true">ÃÉ</mo></mover><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mi>l</mi><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo>‚àí</mo><msubsup><mover><mi>X</mi><mo accent="true">ÃÉ</mo></mover><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mo>‚Ñì</mo><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo stretchy="true" form="postfix">|</mo></mrow><mo>‚àí</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><munderover><mo>‚àë</mo><mrow><mi>l</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mrow><mo stretchy="true" form="prefix">|</mo><msubsup><mover><mi>X</mi><mo accent="true">ÃÉ</mo></mover><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mi>l</mi><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo>‚àí</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo stretchy="true" form="postfix">|</mo></mrow><mo stretchy="true" form="postfix">]</mo></mrow><mi>.</mi></mrow><annotation encoding="application/x-tex">
\widehat{S}^j_{\mathrm{NA}}(H,P) = 
\frac{1}{|L_j|} \sum_{i \in L_j} 
\left[
\frac{1}{2N^2} \sum_{l=1}^N \sum_{\ell=1}^N 
|\tilde{X}_{i,j}^{(l)} - \tilde{X}_{i,j}^{(\ell)}|
- 
\frac{1}{N} \sum_{l=1}^N 
|\tilde{X}_{i,j}^{(l)} - x_{i,j}|
\right].
</annotation></semantics></math></p>
<p>The first term is internal dispersion of the imputed values and the
second term is distance between the imputed and the actual observations.
The larger the score, the greater the uncertainty of the imputation
relative to the true data.</p>
</div>
<div class="section level4">
<h4 id="step-5-weighting">Step 5: Weighting<a class="anchor" aria-label="anchor" href="#step-5-weighting"></a>
</h4>
<p>Each variable‚Äôs contribution to the final score is weighted by:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>j</mi></msub><mo>=</mo><mfrac><mn>1</mn><msup><mi>n</mi><mn>2</mn></msup></mfrac><mrow><mo stretchy="true" form="prefix">|</mo><msub><mi>L</mi><mi>j</mi></msub><mo stretchy="true" form="postfix">|</mo></mrow><mo>‚ãÖ</mo><mrow><mo stretchy="true" form="prefix">|</mo><msubsup><mi>L</mi><mi>j</mi><mi>c</mi></msubsup><mo stretchy="true" form="postfix">|</mo></mrow><mi>.</mi></mrow><annotation encoding="application/x-tex">
w_j = \frac{1}{n^2} |L_j| \cdot |L_j^c|.
</annotation></semantics></math></p>
<p>This accounts for the relative amount of missing and observed data
per variable.</p>
</div>
<div class="section level4">
<h4 id="step-6-final-score">Step 6: Final Score<a class="anchor" aria-label="anchor" href="#step-6-final-score"></a>
</h4>
<p>The final <em>energy-I-Score</em> is a weighted average over all
variables with missing values:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>S</mi><mo accent="true">ÃÇ</mo></mover><mrow><mi mathvariant="normal">N</mi><mi mathvariant="normal">A</mi></mrow></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>H</mi><mo>,</mo><mi>P</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mfrac><mn>1</mn><mrow><mo stretchy="true" form="prefix">|</mo><mi>ùíÆ</mi><mo stretchy="true" form="postfix">|</mo></mrow></mfrac><munder><mo>‚àë</mo><mrow><mi>j</mi><mo>‚àà</mo><mi>ùíÆ</mi></mrow></munder><msub><mi>w</mi><mi>j</mi></msub><msubsup><mover><mi>S</mi><mo accent="true">ÃÇ</mo></mover><mrow><mi mathvariant="normal">N</mi><mi mathvariant="normal">A</mi></mrow><mi>j</mi></msubsup><mrow><mo stretchy="true" form="prefix">(</mo><mi>H</mi><mo>,</mo><mi>P</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>.</mi></mrow><annotation encoding="application/x-tex">
\widehat{S}_{\mathrm{NA}}(H,P) =
\frac{1}{|\mathcal{S}|} \sum_{j \in \mathcal{S}} 
w_j \widehat{S}^j_{\mathrm{NA}}(H,P).
</annotation></semantics></math></p>
<p>This scalar measure summarizes the <strong>imputation
uncertainty</strong> across the dataset.</p>
<hr>
</div>
</div>
<div class="section level3">
<h3 id="practical-interpretation">Practical Interpretation<a class="anchor" aria-label="anchor" href="#practical-interpretation"></a>
</h3>
<ul>
<li><p><strong>High values</strong> of the score suggest large
variability or poor alignment between imputed and observed
distributions.</p></li>
<li><p><strong>Low values</strong> indicate imputations that are close
to the observed data distribution (better performance).</p></li>
<li><p>Variables with few missing values have lower weight, while those
with many missing values contribute more.</p></li>
<li><p><strong>Methods that do not rely on multiple imputation</strong>
or have a <strong>weak/random draw mechanism</strong> tend to perform
worse, because they underestimate the uncertainty of the missing
values.</p></li>
<li><p>The <em>energy-I-Score</em> should primarily be used to
<strong>rank different imputation methods</strong>, rather than to
interpret its absolute numeric value directly.</p></li>
</ul>
</div>
</div>
<div class="section level2">
<h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<p>This approach follows the methodology proposed by N√§f, Grzesiak, and
Scornet (2025) in ‚ÄúHow to rank imputation methods?‚Äù
(arXiv:2507.11297).</p>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Krystyna Grzesiak, Jeffrey N√§f.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer>
</div>





  </body>
</html>
